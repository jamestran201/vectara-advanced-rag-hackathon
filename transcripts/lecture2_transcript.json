{"documentId": "lecture2", "section": [{"text": "Yes. Okay, good. Okay, so the topic for today is threats in RPC. So our second lecture in 6824, and we're going to mostly look at threats in RPC in the context of go, the programming language that we're using in the labs. And in fact, most of this lecture is really tailored towards helping you do go programming for the labs.", "metadataJson": "{\"start\":1,\"end\":27}"}, {"text": "So all of you have done, hopefully, the tutorial and the crawler exercise, which we'll discuss in quite a bit of detail later in the lecture. But before jumping into the details, let me do a little bit more of cold calling to break the ice and get people to ask questions. So maybe you can answer the question, where are you and how did you enjoy the tutorial? What is your first impressions of go? Maybe I'll.", "metadataJson": "{\"start\":29,\"end\":54}"}, {"text": "How about even Veldman? What is your. Hi, folks, I'm Batman. I'm in Newton, which is on the outskirts of Greater Boston. Turtle was interesting.", "metadataJson": "{\"start\":55,\"end\":68}"}, {"text": "It was my first exposure to a non object oriented language. So it's kind of a change in framework that was interesting to adapt to. How about Brendan Wong?", "metadataJson": "{\"start\":68,\"end\":82}"}, {"text": "Brandon, are you there? Yeah, sorry, I was just finding the unmute button. Sorry, what was the question? I just joined. Oh, yeah.", "metadataJson": "{\"start\":88,\"end\":94}"}, {"text": "Where are you and what is your first impressions of go? Yeah, I had used go before for an internship, but it's my first time actually dealing with the concurrency stuff, like really working with go routine. So kind of initially was like tricky to think through. Like as soon as the main thread ends, all to go routines are ended. So kind of working through those early kind of conceptual issues, but it's interesting to kind of think through.", "metadataJson": "{\"start\":94,\"end\":120}"}, {"text": "How about the. Connor Prisbee?", "metadataJson": "{\"start\":120,\"end\":122}"}, {"text": "Connor, are you there?", "metadataJson": "{\"start\":133,\"end\":134}"}, {"text": "Try somebody else. Dori Shen?", "metadataJson": "{\"start\":140,\"end\":143}"}, {"text": "Hi, I'm in Cambridge right now and I found go to be pretty interesting. I thought, like through like the first part of the tutorial, I like, like learning about the for loops and the ways they do for loops. I thought that was pretty interesting and like, the way it's kind of structured. I think that I like the threads I found to be a little bit more difficult about when it ended and when sometimes the function would end before all the routines ended. So that was interesting to think about and I learned more about that.", "metadataJson": "{\"start\":147,\"end\":179}"}, {"text": "So it's pretty cool. I liked it. Well, I hope all of you are going to have a very positive experience with go in this semester. And so let me say a little bit like, you know, why go? And in principle, you know, there are a lot of programming languages that you could have used for doing distributed programming.", "metadataJson": "{\"start\":179,\"end\":199}"}, {"text": "And go is absolutely not the only one. But some reasons why we, why we chose go in 824. You know, first of all, it has good support for threats and RPC, and those two are very important for distributed programming. So it makes sense to go. There's a good match for that.", "metadataJson": "{\"start\":199,\"end\":222}"}, {"text": "Second reason that we like it a lot is it has a garbage collector. And if you do shared memory style parallelism, where multiple threads share a structure or variable, then having a garbage collector is nice because then the threads don't have to decide who's the last that actually has a reference to this memory one and should therefore deallocate it. The garbage collector just takes care of all those problems. So that's convenient. It's type safe, it is simple, it's a reasonable, simple programming language, quite easy to learn.", "metadataJson": "{\"start\":223,\"end\":259}"}, {"text": "And in fact, you know, hopefully you got that experience with doing the go tutorial, that once you do the go tutorial you mostly got most of Google and then finally the hatch on a compiler, so it's compiled unlike Python or, you know, actually the compiler produces executable code and so the runtime overhead is not as large. I guess sort of the final reason why eight to four is in go is because I enjoy writing Go programs. And so that may be also an important reason. So what I'm going to do is I'm going to talk a little bit about threats in general, RPC in general, and talk a little bit about different aspects of programming with threats. Some of this is pre tutorial.", "metadataJson": "{\"start\":259,\"end\":307}"}, {"text": "If you have seen this before, my apologies. I'm going to go reasonably quickly through it. It's definitely not a comprehensive introduction to concurrent programming, but just hopefully enough to remind you what the issues are and what you should look out for. And we'll hopefully spend some time, quite a bit of time on the crawler. And so I'll share you the solution.", "metadataJson": "{\"start\":308,\"end\":329}"}, {"text": "I have two solutions, one using channels and one's using new Texas, and we'll go through both of them. Any questions so far before I sort of dive in?", "metadataJson": "{\"start\":329,\"end\":338}"}, {"text": "Okay, let me get started with threats.", "metadataJson": "{\"start\":344,\"end\":347}"}, {"text": "So thread is basically shorthands of thread of execution in go. A thread is called the go routine, but everybody else basically in the world goes calls a thread a threat. And so the way to think about it is that like when you do go run now, the go will create a process on your operating system, and inside of that process is the go runtime system. And when go starts, it actually has one thread of execution, the main thread, but then it has primitives to create new threads. You can think about this.", "metadataJson": "{\"start\":350,\"end\":387}"}, {"text": "Those are many, many threads of execution running in parallel. And you can think about a single thread as basically a sequential program running. The program has a program counter, has its own stack, it has its own set of registers.", "metadataJson": "{\"start\":387,\"end\":404}"}, {"text": "And so this behaves like a sequential program, like executes instruction one, then execution two, then instruction three, then four, you know, may make a procedure call, allocate memory on the stack, return from a procedure call to a recursive call. Also standard sequential type of programming. It's just like happens as a sequential threat. Basically the interesting thing is that the threads may actually share memory with other threads. So since all the threads are running in the same address space, the same operating system address space, or the same process address space, they can actually share memory.", "metadataJson": "{\"start\":407,\"end\":447}"}, {"text": "So one thread can write to location, say ten, and then another thread can actually read that location ten. And so that way they can actually communicate information.", "metadataJson": "{\"start\":447,\"end\":456}"}, {"text": "One way to think about threat two is to think about it as a sort of an abstraction supported by the runtime. And the runtime has a number of operations on a threat. So one operation we've seen many times, you've seen that many times, is to actually start a threat or create a threat. This is the go syntax, the go keyword. A threat can exit, and generally this just means the access implicit, like when the thread returns from its, you create a function using go, the go keyword, and you return out of the function.", "metadataJson": "{\"start\":458,\"end\":496}"}, {"text": "Then implicitly the threat actually exits the go. Runtime also has a couple other sort of under the hoods operations, if you will. One, it can actually stop a thread. So for example, if a threat writes to a channel and there's no reader on the channel yet, then the threat might get blocked. And so the go runtime sort of stops.", "metadataJson": "{\"start\":496,\"end\":516}"}, {"text": "The thread puts it at site so that it can actually run another thread on the processor, and then maybe later on resumes that thread. So there's a third final primitive that actually is resume threads. And really what it means to stop and resume a thread is basically taking the state of the thread like a program counter. The stack pointer in the register should put it on site, run another thread on the processor, and then at some point decide to resume the processor, which means basically loading the program counter, the stack pointer, and the registers back into the processor so that it started running. So that's sort of a very mechanical view of what a thread is.", "metadataJson": "{\"start\":516,\"end\":554}"}, {"text": "So why you have threads in the first place, that seems like an important point to discuss, because in some ways the only thing that threads do is make your life more complicated as a programmer, like writing sequential code is actually just easier than writing parallel code. And the main reason to have it and the main reason we care a lot about it in six, eight, four is to express a concurrency and sort of three different, you know, two or three different types of concurrency that we actually care about. So we think about our, you know, process. We got our runtime with our threads running. You know, one type of concurrency that we care a lot about is I O concurrency.", "metadataJson": "{\"start\":559,\"end\":604}"}, {"text": "So one of these threads, you know, that is running here, then it might actually make a network call connecting to another machine on the network, you know, to implement a distributed application like Mapreduce. And you know, as it makes a call, you know it's going to be blocked, you know, waiting for a response. And while it's blocked, you know, waiting for a response, it would be nice to actually run some other threads so that we can get more work done. For example, we want to issue multiple requests to multiple machines sort of roughly in parallel. We could just do that.", "metadataJson": "{\"start\":608,\"end\":640}"}, {"text": "We fire off one go routine, then we fire another go routine, another go routine that all send and make connections to other remote machines. That's one reason that we care a lot about it, IO concurrency. The second reason that we care about it is it allows for multicore parallelism.", "metadataJson": "{\"start\":640,\"end\":656}"}, {"text": "So we have multiple cores in our computer or a processor. Then we can have one thread running on one go routine running on one core, and another thread or another go routine running on another core just straight in parallel. And as for example, we implement a key value servers, then we could process maybe requests for different keys in the key value servers on different cores, completely parallel throughput. So those are the two main reasons that we care a lot about concurrency by threats. There's a sort of a third reason.", "metadataJson": "{\"start\":663,\"end\":697}"}, {"text": "You know, there's a little bit of convenience.", "metadataJson": "{\"start\":697,\"end\":699}"}, {"text": "There's going to be a number of cases in the lab, for example, where we want to have something happen periodically, maybe every second or every 200 milliseconds, and we can just launch a thread for that, or a go routine for that. It just sleeps for 200 milliseconds, you know, does what it needs to do, and then it goes back to sleep for 200 milliseconds seconds. And so it's convenient to sort of have these sort of background activities that need to be done periodically. And you can express that using threads. Of course you can express them in other ways.", "metadataJson": "{\"start\":703,\"end\":729}"}, {"text": "The threads are actually convenient. Another question that comes up often, and I think it came up in some of the lecture questions today, like how many threads should you create? And I think the go designers, the way they want you to think about it, is that you should create as many threads as you need. They're definitely not free when they tie up some memory because you have to have a stack. There's some performance overhead with starting them, but you should think about them as very lightweight.", "metadataJson": "{\"start\":729,\"end\":756}"}, {"text": "So you should be encouraging or you're encouraged to create threats as you go. Any questions about sort of this basic reason or why to have threats?", "metadataJson": "{\"start\":757,\"end\":768}"}, {"text": "Okay, let me then. You know, as I said, I mentioned earlier, threats actually have challenges.", "metadataJson": "{\"start\":774,\"end\":781}"}, {"text": "Programming with threats has challenges. So let me talk a little bit about the challenges. I'm not going to go in great amount of depth here. I assume that, you know, they all make sense. And we'll become more clear if we look at some of the examples.", "metadataJson": "{\"start\":783,\"end\":796}"}, {"text": "And probably the main reason that, you know, threats actually are challenging is that you can have race conditions.", "metadataJson": "{\"start\":796,\"end\":802}"}, {"text": "And just like a basic example of a race condition, let's say you have two frets. You know, here's t one, here's t two, and they share variable n. Let's say the initial value is zero and they both execute. Both threads execute a statement to form as the increment n by one. Of course, you might think that statement is an atomic operation or something that is indivisible, but it isn't the go statement that gets compiled to whatever instructions the processor is executing.", "metadataJson": "{\"start\":810,\"end\":843}"}, {"text": "We cannot assume that's an atomic instruction. In fact, it consists of basically a load which stores the content of n into a register, then increment the register, then store the register back into memory. So if you're very unlucky, if the two threads basically try to both execute this particular instruction, then we can have a very unfortunate sequence of events where both reds performed a load instruction. Load the variable in register, let's say r zero here also in r zero, they increment it. So r zero becomes one becomes one, and then write it back to restore instruction that actually results, stores the results back into the variable n in memory.", "metadataJson": "{\"start\":844,\"end\":896}"}, {"text": "So if this happens at this PArTiCULAR, in this SceNARio where this happens truly concurrentlY, what is the value of n after these two threads? They both in incremental, just one. Yeah, it's one. And what is the value supposed to be? Or what would you expect it to be?", "metadataJson": "{\"start\":898,\"end\":917}"}, {"text": "Two. Yeah, expect it to be two. Right. And so one is definitely not equal to two. And there's a bug.", "metadataJson": "{\"start\":922,\"end\":927}"}, {"text": "And so, and this is like, you know, the sort of the heart of race conditions, which is that, you know, if an unfortunate, unfortunate sequence of events where threats share the updates actually might not be reflected correctly. And of course most of the time this will work out fine because you just have to be in this sort of very sort of this very specific case before it shows up. So for example, I think one of you reported, oh, I didn't have my locks or my race, my locks in order and my program just worked fine. And others actually the real issue with rage conditions, they typically just work fine, but sometimes it goes wrong. So the two ways to address race conditions.", "metadataJson": "{\"start\":928,\"end\":973}"}, {"text": "The first way is to avoid sharing, don't share variables. And this is one style of programming that go encourages by using channels, channels you just communicate values, but you don't really directly share memory. So that's one way of doing it, another way. So avoid sharing is one big approach. The other approach is actually to use locks to make a sequence of instructions in atomic operation.", "metadataJson": "{\"start\":973,\"end\":1002}"}, {"text": "We'll talk a lot more about that in a second. One of the things that I want to point out that is really cool about what is useful tool is go actually has a race detector. And most of the labs that you were doing would encourage you to basically run go using the race flag. And that will actually not catch every possible race, but it does an extremely good job of actually identifying races. And so you should by default run go with the race detector enabled.", "metadataJson": "{\"start\":1002,\"end\":1031}"}, {"text": "Okay, so that's one challenge with threats. The second challenge with threats is actually coordination. So it's often the case that one has to, one thread must wait on another thread before something is accomplished. The number of the go exercises in the tutorial had that kind of form. And there's two ways go excellence through primitives.", "metadataJson": "{\"start\":1033,\"end\":1054}"}, {"text": "We're dealing with that one again, channels. Channels basically allow you to communicate and to coordinate at the same time, or which I'll talk a little bit later about condition variables, and both can be useful. I'll talk a little bit more about that. And then finally, final challenge, big sort of conceptual challenge, is you can get that lock. So if one friend waits, like t one waits on t two and t two waits on t one, you know, before example, that release your lock or before some other sequencing, you can basically sort what I call deadly embrace, you know, where both were waiting on the other.", "metadataJson": "{\"start\":1054,\"end\":1098}"}, {"text": "As a result, nothing makes for progress.", "metadataJson": "{\"start\":1099,\"end\":1101}"}, {"text": "A trivial way of getting, you know, say, deadlock in a go would be like you have a single threat, there's no other threads at all, and you're right to channel and that will block that one thread until somebody else reads, some other thread reads from the channel. But if there's no other thread at all, that will result in a deadlock, just like the simplest possible deadlock possible. And go actually will catch this case and we'll raise a runtime error saying no threats can run, you have a deadlock, but there can be more complicated dev blocks involving multiple threats. And as you're going through the labs in the semester, I'm sure you will run into some.", "metadataJson": "{\"start\":1103,\"end\":1144}"}, {"text": "So take a little bit of a step back here and think about, you know, go for, you know, these challenges that I just talked about. Roughly speaking, go as sort of two plans to handle these concurrency challenges. And one plan is, you know, basically around channels, and there's another plan basically around locks and condition variables.", "metadataJson": "{\"start\":1147,\"end\":1181}"}, {"text": "And the way I think about it, some people are quite dogmatic about this and think one plan is better than the other plan. My general approach here is I usually want the plan that is most suitable for the case that I'm looking at or that I'm running into. And generally I have no sharing. And basically I need two threats basically to communicate, but they don't really share any memory. I tend to use channels if there are two threads that do share memory because it's convenient to share memory.", "metadataJson": "{\"start\":1191,\"end\":1222}"}, {"text": "For example, I write a key value server and I want to share the key value table. Then I use locks and condition variables.", "metadataJson": "{\"start\":1222,\"end\":1233}"}, {"text": "And so my general approach is not so to be dramatic and take whatever approach that actually is most convenient for the problem at hand. The tutorial does a pretty good job of actually teaching you about channels mentioned. Locks doesn't say much about condition variables. So I think it's worthwhile to talk a little bit about condition variables to make sure that you're aware that they exist. And I'm going to do that using a tiny little example to sort of illustrate the issues.", "metadataJson": "{\"start\":1238,\"end\":1270}"}, {"text": "The tiny little example is we have a little bit inspired by the labs, we have a threat, t one. And t one needs to collect a number of votes from remote machines, for example, it needs to decide if it has a majority so that it actually proceeds to commit some value. And you'll see that later in this shows up in the raft lab as one of the primitives that you need. And so to do that, t one will fork other threats like say, t two and t two, amazingly, does something expensive like talk to some remote machine to actually get its vote, and then reports back that vote to t one. And t one basically needs to collect all the votes, add them up, and then assume that they're majority, then declare sort of victory.", "metadataJson": "{\"start\":1271,\"end\":1323}"}, {"text": "So this is a pretty straightforward, simple program, but it gives you a little bit of. Allows me to illustrate you a couple of issues. So I'm going to switch to another screen. Can everybody see this?", "metadataJson": "{\"start\":1324,\"end\":1338}"}, {"text": "So here I have a very simple implementation of this program, the vote thing. And again, it's a little bit of a toy example, but just hopefully gets the points across. The two variables shared here, count and Dinish counts, number of votes, finish count when we're done. So, you know, there's a loop going to go for ten, creating a go creating, launching on an anonymous function and an anonymous function concurrently calls this function request vote and request vote basically simulates doing a long, expensive operation on some remote machine. And the way it simulates it is by just going to sleep.", "metadataJson": "{\"start\":1342,\"end\":1387}"}, {"text": "It blocks for a little while, then it returns, and then, you know, it returns. Voted yes. Then the count goes up and we count the fact that actually we had one more threat voting, and then we're done. So we fork off ten threads, each of them request vote, and report the result. And then at the end we'll check if the count is smaller than five.", "metadataJson": "{\"start\":1387,\"end\":1409}"}, {"text": "We know that we failed, we lost the election. And if we have votes equal larger than five, you know, we basically won the election. So this is sort of the simple, very simple program. Does it all make sense? Let me run it just for the kicks and, you know, run it a couple times.", "metadataJson": "{\"start\":1409,\"end\":1435}"}, {"text": "Sometimes we lose, sometimes win, you know, makes sense. And so this program looks working and correct. Is it actually correct?", "metadataJson": "{\"start\":1435,\"end\":1445}"}, {"text": "Sorry, was the question whether this program is actually correct? Yeah, it seems to produce results.", "metadataJson": "{\"start\":1449,\"end\":1455}"}, {"text": "I think there's a race condition, isn't there? Like you have all of these different threads incrementing the count and finished variables. Yeah. And it's also, it's not clear to me that finished necessarily always reaches ten. Is it possible that it doesn't?", "metadataJson": "{\"start\":1458,\"end\":1477}"}, {"text": "Let me, let me take these one by one and just go over your first point, which is the one I was after. Clearly this has the fact we have two variables here. Correct count diminished. They're accessed by different go routines. So this is immediately a red flag.", "metadataJson": "{\"start\":1479,\"end\":1496}"}, {"text": "It could be a serious problem here. As soon as you have a variable that has access to or modified and by two different go routines, you know, there's got to be a problem. And so, you know, interesting to run the race detector and see if it actually catches it. And as you expected, you know, the goal, the race detector, tells you exactly, you know, there is indeed, you know, some problems here with this program. And list the line numbers where things actually can go wrong.", "metadataJson": "{\"start\":1496,\"end\":1521}"}, {"text": "So that gives you actually a pretty good clue that something is not up to snuff this program. And so we're going to repair it in small steps and that will hopefully shed some more light on concurrent programming. So let me use my second solution to this program, and in this case I'll talk about channels a little bit later because I wanted to illustrate locks and condition variables first because they got less emphasis in the tutorial. So, you know, simple solution, you know, go correct, you introduce a lock. The lock is completely independent of the variables and you follow some convention which says like, well, this log new protects count and finish.", "metadataJson": "{\"start\":1523,\"end\":1567}"}, {"text": "And so whenever, you know, you access count to finish, basically you have to wrap that into a lock and an unlock statement. And so here we see two like this is the go function that runs concurrently. And after you know the request code, it's about to update the vote and finish. So we take a walk out and then go. Has this nice feature called the defer statement that if you exit the basic block, you know, we'll run the function that is declared by the deferred after the keyword deferred.", "metadataJson": "{\"start\":1568,\"end\":1600}"}, {"text": "And so this means like we execute, we leave the go function here, will automatically unlock. This is convenient because then you won't forget to unlock. And so it's nice to do that, right, a point where you do the lock and so you can write immediately defer, unlock, and then you don't have to worry about if there are multiple exit paths out of a go routine or out of function that you forget to unlock. So now, you know, we're basically in a critical section where we hold the lock, we update, vote and count, and then of course the function returns and locks automatically. Similarly, at the end we got a every time we access count to finish, since they share it, we need to surround it with locks.", "metadataJson": "{\"start\":1600,\"end\":1644}"}, {"text": "Simple way of doing it. We could have written d for unlock here too, in the body, but it would be fine. We can actually run this program. Let's see, we run it. The race detector seems to be happy.", "metadataJson": "{\"start\":1645,\"end\":1660}"}, {"text": "Hopefully we'll have a better program. So I just have a question here about scoping. So it seems that when we have the anonymous function, then we have this mu and we have the count and we have the finished. And it seems that the anonymous function has access to variables that were defined outside of the function. So how do rules work?", "metadataJson": "{\"start\":1660,\"end\":1678}"}, {"text": "Yeah, with an anonymous function, any variable that's used inside of the function, that's not declared inside of the function, basically result points to variables outside of the outer scope. So statically scoped. What about the scope of like the mutex? How many times you have to declare that? And what's the scope of it?", "metadataJson": "{\"start\":1679,\"end\":1703}"}, {"text": "I guess the scope of the deferred statement is this block one basic block. No, I mean when you actually declare like the mutex data structure, I guess it's like any other variable. It has the same scope as finished or count. So it applies to any variable declared in. The rest of the way to think about it is that the mutex is not directly associated with any variable.", "metadataJson": "{\"start\":1703,\"end\":1730}"}, {"text": "It's just a lock. It's like a name. And it's up to you as a programmer to decide what that lock protects.", "metadataJson": "{\"start\":1731,\"end\":1737}"}, {"text": "They're two independent concepts.", "metadataJson": "{\"start\":1741,\"end\":1743}"}, {"text": "What happens if you use I in the go routine? That wouldn't work, right? You need to pass that in. Yeah. So what are those?", "metadataJson": "{\"start\":1745,\"end\":1752}"}, {"text": "A good question. And a number of, you asked that for email too. So what happens to like, if we use I here and what, you know, do something with it? Like whatever count is I, is this a good plan or not?", "metadataJson": "{\"start\":1752,\"end\":1766}"}, {"text": "What value of I will we be using when this thread actually happens to run? If a node starts to function and we'll run at some point, what value of I will, we're using whatever I happens to be at the time which is being changed by the, for loop outside. Yeah. Correct. So, you know, so this is not so great.", "metadataJson": "{\"start\":1771,\"end\":1791}"}, {"text": "That's probably not what we intended, right? We probably intended the I that we whatever for that specific loop iteration. Right. So how do we want to, if we have to solve that, how would we do? You could add it as a parameter to anonymous function and pass it in so that it gets evaluated when you create the go routine.", "metadataJson": "{\"start\":1791,\"end\":1809}"}, {"text": "Yeah. So we just write this and then pass it actually in. Right. And then a point. What happens then?", "metadataJson": "{\"start\":1809,\"end\":1815}"}, {"text": "At the point we actually create the go routine, I is being captured and then passed in. Okay. Can I ask, how are the local variables allocated? Like if count and finished are like local variables, wouldn't they be destroyed after the main function exits? Or like if this wasn't main, but like another function, what if like the containing function exited before the go register?", "metadataJson": "{\"start\":1815,\"end\":1841}"}, {"text": "Yeah. They're in principle allocated in stack. And you know, presumably the other functions have these memory addresses, references to them. So it's indeed the case as main returns. Then these stack allocated variables are gone.", "metadataJson": "{\"start\":1841,\"end\":1856}"}, {"text": "So typically what you will see is that in a Go program you would allocate them in on the heap using new, like if you make a new struct or whatever. So would you get a segmentation fault then, or would it just, yeah, you would get error. Okay, I have a question. I actually remember this is the correct way to do it or not. But instead of passing it in, would it be possible to, as the first line in the for loop, do I colon equals I, and then you're like, you have a, I don't know how the scoping works within the like block of the for loop because I think that should create a new variable I that the go routine can access that isn't being updated again.", "metadataJson": "{\"start\":1856,\"end\":1896}"}, {"text": "Right. You can do that. That can help. Instead of passing it in, it kind of makes it look ugly to me. Okay, well, I like the passing in, but that's another way of doing it.", "metadataJson": "{\"start\":1896,\"end\":1905}"}, {"text": "I'll show an example later.", "metadataJson": "{\"start\":1905,\"end\":1907}"}, {"text": "So somebody asked, actually, you know, do we get a segmentation fault? We're not immediately going to get a segmentation fault. I should take that back because basically one thread will still hold a reference. So the garbage collector will not delete the object yet, right? Only when the last fret, actually only when no thread holds a reference, you know, will the garbage collector delete the object.", "metadataJson": "{\"start\":1909,\"end\":1932}"}, {"text": "And this is one of the cool things about having garbage collected language and shared memory programming. You don't have to worry about that scenario.", "metadataJson": "{\"start\":1932,\"end\":1939}"}, {"text": "Okay, there's a, yeah, would, could this code like deadlock? Because like if we, if, like the go routines, like the first for loop will exit and then the second one will like, yeah, no, nevermind. Okay. There are definitely some issues that are not ideal yet, so let me actually talk about them. One of them is that like this particular loop, it's a little bit annoying, right?", "metadataJson": "{\"start\":1941,\"end\":1969}"}, {"text": "Like this for loop is there's nothing else than waiting until count reaches five or finished. And the way it does is by just spinning, right? So it just locks, locks it, looks at the value, quickly unlocks it and spins around again. So basically spinning on the processor doing really nothing. It'd be nice to express that in a little bit better way so that like basically the go can sort of give up the core and so then another threat can run.", "metadataJson": "{\"start\":1969,\"end\":1990}"}, {"text": "And so the way you can do that is using condition variables. And so this is my, the next implementation, or actually, I'll show you one other implementation. Well, one way to do that, it's a little bit not so nice. For example, and what somebody suggested this is to actually sleep for a little while. So instead of like uh, giving up the spinning like crazy, just sleep for one and periodically sleep for a period and then come back.", "metadataJson": "{\"start\":1990,\"end\":2015}"}, {"text": "Of course the solution will work. But the downside of it is that, you know, how, how long should you sleep, right? You really would like to be the case that soon, for example, this guy reaches five, uh, then, you know, you wake, you know, you could wake up the, this particular, you know, the main threat. And so I was jumping ahead a little bit, but so that's what condition variables are for. And you know, here's a solution with condition variables.", "metadataJson": "{\"start\":2015,\"end\":2040}"}, {"text": "So we allocate a new condition here. The condition variable is allocated. It's associated with this particular lock. We'll see in a second why this is important. And you know, basically the main thread, what it does now, it grabs the log because it needs to grab the lock to look at count and finished.", "metadataJson": "{\"start\":2041,\"end\":2060}"}, {"text": "Otherwise there could be erase conditions. And then if the condition is still not true, it just calls wait on this condition variable. And what that does is actually, that atomically goes to sleep as well as releasing the lock that is associated with the condition variable. Since mu is actually associated with the condition variable, condway basically unlocks the lock and goes to sleep in an atomic operation. And when it returns from count wait, it will actually hold the lock again.", "metadataJson": "{\"start\":2060,\"end\":2093}"}, {"text": "So the caller knows, we're absolutely sure that if conduit returns, it will actually hold the lock again. And so it's safe again to look at count and finish and then call wait again. Okay, so basically, you know, this friend will go to sleep, and then the go routines that are collecting the votes, same code as before, lock and unlock or defer to unlock. And then when you're done, you know, updating count to finish. There are two primitives on the condition variable.", "metadataJson": "{\"start\":2093,\"end\":2122}"}, {"text": "One is signal and one is broadcast. And broadcast, basically signal wakes up one waiter and broadcast wakes up all waiters. You know, there's only one waiter here, so we could have used either one of them. And so basically when it reaches, you know, five, you know, at some point, or ten, then, you know, the, so every time finish is incremented, you know, the main thread will be woken up, it can check the condition and then keep going. Okay, so this is convenient, sort of, you can think about condition variables as a coordination primitive, you know, between two different threads.", "metadataJson": "{\"start\":2122,\"end\":2156}"}, {"text": "And they're particularly convenient when you're actually using locks, you know, for, to protect your shared state.", "metadataJson": "{\"start\":2157,\"end\":2162}"}, {"text": "So here's the same implementation of this program. Using channels, more or less works the same way, except of course no locks, but the main thread creates a channel, passes the go routine, the anonymous function that is being created as a separate thread. It writes basically the request vote to the channel. And then the main thread basically blocks here. Correct.", "metadataJson": "{\"start\":2170,\"end\":2196}"}, {"text": "When it starts reading from the channel, once it actually gets something, when something is written to the channel will unblock, you know, look at the value and if it's true, add up and always increments finish. And what's going on here correctly is we don't need locks because count and finish are not shared. There's only one thread that actually updates count and finish, and that's the main thread. Okay. The uh, and this, this, you know, the, the main, the, the sort of request threats, you know, all basically just write to this, uh, channel.", "metadataJson": "{\"start\":2196,\"end\":2231}"}, {"text": "They write concurrently perhaps to the channel, but the channels is one of the things in go that actually our thread saved. So multiple threads can actually write to the channel.", "metadataJson": "{\"start\":2231,\"end\":2239}"}, {"text": "Um, any questions about this, about the solution?", "metadataJson": "{\"start\":2241,\"end\":2245}"}, {"text": "What was the thing about like, having a buffer for the channel? Yeah. So normally when you're writing to the channel and nobody's reading from the channel, or no thread is reading from the channel, then the center will immediately be blocked. You can specify that the channel has a buffer, say of ten or 20, and that allows the channel to have multiple values in eight to four labs. I've never used buffered channels.", "metadataJson": "{\"start\":2247,\"end\":2278}"}, {"text": "And one of two, three times I did it, you know, I regretted it. So in general, I don't use it. But this raise an important point. This program is actually still not very good. So for example, when it doesn't matter in practice, in this particular example, but it's not in some of the labs, that could bite you.", "metadataJson": "{\"start\":2278,\"end\":2300}"}, {"text": "As soon as it reaches count five, what will happen?", "metadataJson": "{\"start\":2301,\"end\":2304}"}, {"text": "It stops listening for listening to the channel. So any other threads are just going to be blocked? Yeah. So basically it means like if the first five threads voted yes, then the next five threads will be blocked in this channel. Correct.", "metadataJson": "{\"start\":2307,\"end\":2321}"}, {"text": "They will be hanging around. And in this case it won't be a problem, because as most of you guys, most observed like that, if the main thread exit, it actually cleans up all the other threads too. But for example, if this be a long running service, this would be not good. Basically, we're leaking threads here. They're sitting blocked on the site, doing nothing in that channel.", "metadataJson": "{\"start\":2322,\"end\":2345}"}, {"text": "And so that's quite inconvenient. And this is something to watch out for. And this showed up in the crawler, I think for many people.", "metadataJson": "{\"start\":2345,\"end\":2352}"}, {"text": "The flip side of this is that if the main threat enters too early, before any of the request votes are done, then you also have a problem. And so there's management of threads that actually is often a tricky issue. Is there a way to kill the thread without exiting from main? Well, you can send it a variable or value on some channel saying like please exit, but you have to coordinate it yourself.", "metadataJson": "{\"start\":2355,\"end\":2381}"}, {"text": "I want to go back to one of the things that actually is cool about condition variables is that in principle you might think the same issue exists here where this thread actually runs and this thread might get blocked. For example, if we reached zero five, this main thread will perceive doing its thing while the other guys are still maybe actually sitting in here. But notice these, in this case they won't be blocked because it grabbed the lock, then does its thing, does a broadcast. And the broadcast is actually not a blocking operation. So unlike writing to a channel that is a blocking operation if nobody is listening, the con broadcast is not a blocking operation.", "metadataJson": "{\"start\":2387,\"end\":2438}"}, {"text": "This actually works out in this particular program by itself correctly. Okay, okay, good. Any further questions about, you know, these two examples, just to.", "metadataJson": "{\"start\":2438,\"end\":2454}"}, {"text": "Okay, then let's talk about the crawler.", "metadataJson": "{\"start\":2460,\"end\":2462}"}, {"text": "So the crawler is also a more realistic example of concurrent programming.", "metadataJson": "{\"start\":2465,\"end\":2470}"}, {"text": "Yeah, just to remind you, basically the idea is that you start out with a URL for some web page. You fetch, you fetch the webpage, it might have more URL's and you basically proceed then fetching those web pages, looking at those URL's and you keep going. The idea is to crawl basically the whole Internet for all the web pages that exist. And of course some URL's might point back to a web page that you already visited. And so the goal is to actually not visit the same web page twice.", "metadataJson": "{\"start\":2474,\"end\":2510}"}, {"text": "And so the goal of the exercise is a couple goals that you want to achieve. One is IO concurrency.", "metadataJson": "{\"start\":2512,\"end\":2518}"}, {"text": "The fetch operation is, may take a long time. Maybe it's a web page that sits on the other side of the world, maybe goes over slow networks. And while you're sort of one thread is fetching that page, you would like to be able to fetch other pages. Another goal is this correctness goal or performance goal, namely fetch one, fetch a URL once.", "metadataJson": "{\"start\":2523,\"end\":2546}"}, {"text": "And you know, presumably you'd also like to exploit multiple cores. If you have multiple cores you can do it, work in parallel.", "metadataJson": "{\"start\":2549,\"end\":2556}"}, {"text": "Okay, so what I'd like to do, before actually talking about the current coherence solutions, first let me show you a simple serial solution so that we have something to talk about as a baseline.", "metadataJson": "{\"start\":2562,\"end\":2581}"}, {"text": "So I have three solutions in here.", "metadataJson": "{\"start\":2592,\"end\":2595}"}, {"text": "Run them, run serial solution. One with mutexes and one with channels. You know, you see that more or less they produce the same result. You know, two found, one missing, two found the only difference is that the order of the output is slightly different once in a while. And of course it has to do with concurrency.", "metadataJson": "{\"start\":2598,\"end\":2622}"}, {"text": "Okay, so the main function calls serial with the starting URL, the fetcher, and then an empty map. And then the serial solution is basically sort of standard sequential recursive solution. We'll first check if we already visited the URL that's passed into us. If we did, then we return immediately. Otherwise we mark it as visit.", "metadataJson": "{\"start\":2623,\"end\":2648}"}, {"text": "We'll fetch the URL that gives us a bunch of new URL's. We look through all the URL's and go basically serial again. Right. And this is your sequential solution as you would expect it. And your goal was to basically write a current version of this.", "metadataJson": "{\"start\":2648,\"end\":2663}"}, {"text": "And so what I like to do is actually to make the class a little bit interactive. I want to go switch over to breakout rooms and what we're going to do is basically put four to five of you in a single breakout room for about ten minutes. And I would like you to do is share your solution with each other and discuss it. So maybe the best way to go about it is that one of you, you get into the room, one of the persons in the room basically screen shares their solution and discusses one of the issues that he or she ran into. And other people can comment or share other solutions and just to get into the discussion and meet some other students in the classroom.", "metadataJson": "{\"start\":2664,\"end\":2706}"}, {"text": "Any questions about that?", "metadataJson": "{\"start\":2707,\"end\":2708}"}, {"text": "Okay, good. Let me go back to sharing my screen again. Can everybody see my screen again?", "metadataJson": "{\"start\":2711,\"end\":2719}"}, {"text": "Yeah, looks good. Good. Thank you.", "metadataJson": "{\"start\":2721,\"end\":2724}"}, {"text": "Okay, so hopefully that was interesting and let me, you know, talk about, you know, the solutions that I have. They're posted on the schedule page. If you haven't, you can look concurrently with me if you want to. There should, you know, let me walk through the Mutex version first and then I'll walk through the Channel 1 second. So here's the, the mutex one.", "metadataJson": "{\"start\":2729,\"end\":2760}"}, {"text": "The mutex one declares a struct that has both the map and the mutex. And the map needs to be protected by mutex because there's going to be concurrent access to the map. So map by itself is not Fred say it's up to the programmer to actually make the map fret save. And the contained mutex one works sort of similar to the serial one except whenever there's shared state. Basically takes a walk out.", "metadataJson": "{\"start\":2760,\"end\":2783}"}, {"text": "So we'll take the lock, we look at the URL fetched. If it hasn't been fetched, we mark it as now being fetched or haven't been fetched and we're in lock and we kept this already valued to decide whether we should return or not. And then this go routine starts fetching a page gets a bunch of URL's back, and then for every URL back it creates a new go routine. Here on this side, passes in the URL that that go routine is supposed to fetch and crawl. The only sort of other interesting thing here is that it uses something called weight group.", "metadataJson": "{\"start\":2783,\"end\":2826}"}, {"text": "And weight group is a very convenient primitive to keep track how many threads you still have active and when you can terminate. And this was a really sort of a big issue in this particular assignment, that if you terminated too early, then you didn't crawl all the web pages. And so you need to keep track whether there's still outstanding web pages to be crawled. Sync weight group does it very easily. Basically, every time you call a thread, you call add, and then when the threat terminates, you call done.", "metadataJson": "{\"start\":2826,\"end\":2856}"}, {"text": "And you conveniently do that in the defer statement. And then the main thread that is waiting for the fret determinant just calls wait and wait will return until every fret that was started, every add one, if all those threads actually have been exited. And so that's the mutex version.", "metadataJson": "{\"start\":2856,\"end\":2877}"}, {"text": "And you can think about sync wait as sort of being internally implemented using a condition variable. Okay, let me look at the channel version. So here's, the channel version is basically sort of organized as the Mapreduce lab where there's a coordinator and workers. And so we start off, we start off creating a coordinator thread. And the way we do that actually is we make a channel.", "metadataJson": "{\"start\":2880,\"end\":2912}"}, {"text": "And then we pass that channel into the coordinator. The coordinator, of course, has to start with a URL, the beginning URL. So we need to supply that on the channel. That's the most convenient thing to do, as we'll see in a second. But you know, to send it on a channel, we basically have to create a go routine because otherwise we deadlock here.", "metadataJson": "{\"start\":2912,\"end\":2929}"}, {"text": "And this is a typical thing go to just send that value on the channel. So let's look at the coordinator. Here's the coordinator. It doesn't use any locks at all because the data structures that, there's no data structures actually being shared, like fetched. You know, the map that actually keeps track of which URL's has been fetched is actually only accessed within the coordinator.", "metadataJson": "{\"start\":2930,\"end\":2955}"}, {"text": "So the coordinator got a, you know, when we called it initially, we got a, it has one URL, it checks the fetch map. And then for every URL then it goes, basically, you know, cycles through channel using a range statement. And basically what this does is it just keeps reading the channel and just grabs the next value, gives the next value, graphs the next value, so basically grabs the URL. We know there's one in it because, you know, we put it on when we created it. And then for that URL we sort of roughly do the same thing as the concurrent, as the mutex one.", "metadataJson": "{\"start\":2956,\"end\":2993}"}, {"text": "We see if the URL has already been fetched. If it hasn't been fetched, then we're done. Otherwise we'll create a go worker to actually fetch that URL.", "metadataJson": "{\"start\":2994,\"end\":3004}"}, {"text": "And we keep track of how many outstanding workers we have. So n is counting the number of workers, and only when n is zero do we terminate the coordinator to make sure that basically we have fetched all the web pages that we're supposed to be fetching. Let's look at a worker. Worker basically calls fetch. This of course, now happens completely in parallel with any other workers.", "metadataJson": "{\"start\":3007,\"end\":3029}"}, {"text": "If it actually fetches some URL from that webpage, it basically writes all those URL's to the channel. The coordinator will get all those channels through its range statement. Then when it's done writing all the URL's through the channel, then the coordinator or the worker exits. And that will, you know, at some point decrease, you know, n and then at the end. And that's it basically.", "metadataJson": "{\"start\":3031,\"end\":3060}"}, {"text": "Okay, so those are the two solutions. Any questions about these?", "metadataJson": "{\"start\":3061,\"end\":3065}"}, {"text": "This is all clear.", "metadataJson": "{\"start\":3072,\"end\":3073}"}, {"text": "There's a question in chat. Ah, good. Let me get my chat list back up.", "metadataJson": "{\"start\":3075,\"end\":3082}"}, {"text": "Okay, so the question is when ch has a value in it, when all other threads be idle. It is the case that the, since this is not a buffer channel, there's going to be only one request in the channel at the time. And so all the threats, you know, will be appending to the channel one by one. But doesn't that make the program sequential because no two threads are running in parallel except the main thread and one, well, the fetches will still happen in parallel. And those are presumably the expensive operation.", "metadataJson": "{\"start\":3092,\"end\":3126}"}, {"text": "Those go out across the Internet. Got it. Thank you.", "metadataJson": "{\"start\":3126,\"end\":3130}"}, {"text": "Okay, let me switch back to my other screen and talk a little bit about RPC, since that's the other thing tool that you need for the labs.", "metadataJson": "{\"start\":3133,\"end\":3144}"}, {"text": "I'm not going to say a ton about it, but there's a RPC which stands for remote procedure call.", "metadataJson": "{\"start\":3147,\"end\":3155}"}, {"text": "And basically the goal, you know, the goal of an RPC system like the one that go has is that they, RPCs behave roughly similar to procedural calls, local procedure calls that you execute on the stack. Right. And so the goal is that, for example, if you have a client, in RPC terminology, the caller is typically called the client and the colleague is called the server. Say you have a function, you know, fn that we're calling with x and y. And then at the server there's the implementation of this function.", "metadataJson": "{\"start\":3161,\"end\":3196}"}, {"text": "And so there's a function and whatever x, you know, from a Y int and you know, it returns, you know, whatever does some computation, but maybe it just returns x plus. Yeah. And so what we like, sort of like to have happen or like the model that we would like ourselves to think about is that when the client calls its function fn, the RPC system will make sure that there's an corresponding happening on the server side, passes the arguments x and y to the server. The code runs on the server. It returns a result, you know, say, you see, and that result is then communicating back to the client.", "metadataJson": "{\"start\":3198,\"end\":3242}"}, {"text": "And, you know, and then fn will resume, will return, and the client will return, will resume with, you know, the x plus y in the value of x plus y in z. Right. So this looks like, you know, even though the programs are running on different computers, you know, they're not sort of a hard boundary here. It looks like, you know, they make sort of regular procedure calls. And we'll see in a second that actually we can make a lot of similarities or it's possible to make them behave very similar.", "metadataJson": "{\"start\":3242,\"end\":3272}"}, {"text": "But we'll see there's also a sort of a fundamental difference and that actually has to really do with distributed computing. But before getting there, let me first sort of sketch out how you can make this work. And this is sort of roughly, you know, what go does too. So the way, you know, to think about it is that when the client, so here our program, and when the client calls the function fn with x and y in it, what it does, it actually calls something what's called a stop. And a stop is basically a local function, you know, called fn.", "metadataJson": "{\"start\":3272,\"end\":3304}"}, {"text": "And with the two arguments declared with x and Y. And basically what the stop does, you can think of this as a stop procedure. And what stop procedure basically does build a message saying which function needs to be called the arguments of the function, the types of those arguments, the values of these arguments, et cetera, et cetera. And then what the stub does actually it sends it over the network to a corresponding stub at the server.", "metadataJson": "{\"start\":3304,\"end\":3336}"}, {"text": "So the server receives this message and basically takes this message. And Marshall, this is the term that's being used to basically convert values from two byte arrays and byte arrays back to values and then calls this function fm at the server fnx int blah blah blah.", "metadataJson": "{\"start\":3338,\"end\":3367}"}, {"text": "So the stub basically calls the function, the function returns back into the stub. The stub marshals the response value like z, x plus, y and sends the back to the client stuff. And the client stuff is still waiting. So basically the client stuff, the way it actually works, it sends out the request and then waits for the response. And so when the response comes back in marshalls and then returns the value to the client.", "metadataJson": "{\"start\":3369,\"end\":3400}"}, {"text": "So basically these two stuffs sort of make a remote procedure call look like a regular procedure call for almost, you can't tell and the key and these stops are generally automatically generated. So the compiler, like in case of the code compiler will generate these steps for you and do the marshalling and inter marshaling arguments for you. And that's how it goes. Oh, so the, so when you're doing it from the server to the client, there's also another stub. Again, you basically return back to that first stub.", "metadataJson": "{\"start\":3400,\"end\":3439}"}, {"text": "So this stub makes a procedure call to major calls the procedure fn. That procedure returns correct into the stub because the stub called it. Oh, it's the same stub that it goes in. Exactly. Got it.", "metadataJson": "{\"start\":3439,\"end\":3452}"}, {"text": "Okay. Okay, so let me show you sort of how this plays out inside of go and by showing you a very simple key value server. And you'll see, you know, it doesn't look exactly their procedure calls, but it is pretty close. So the typical thing is that, you know, you actually declare typical convention sort of goal is that you declare the arguments as structs. And so we're going to implement two procedures, two remote procedures.", "metadataJson": "{\"start\":3452,\"end\":3489}"}, {"text": "One is put and one is get and put is basically put orcs is the arguments to the put and put replies to response. Similarly there's a get Rx with the request or the arguments to the request get procedure and a reply. And so let me first look at the server. So here's our two functions, you know, actually the two functions that we're going to be calling on the server. I think I'll skip down for that for a second, maybe actually, let me talk about them a little bit.", "metadataJson": "{\"start\":3489,\"end\":3523}"}, {"text": "So this is the client side. So the client calls the function get and what inside of get, you know, you, this function actually connects to the server and we'll see in a second what that means. It fills in the arguments, it allocates a response and then calls this procedure client. It calls call. You can think about this as a generic stuff that basically takes the method that needs to be called on the server and the arguments and the reply.", "metadataJson": "{\"start\":3523,\"end\":3547}"}, {"text": "And so call always has three arguments, the method, the argument and the response, and then call internally. We'll send Marshall the arguments, send the message to the server over the connection and wait for the response. The reply, when the reply comes in, the reply struct will be filled in by the call stub. And then when that's done, then return after the call and basically put looks exactly the same way. And so on the server side, let's see how that is implemented.", "metadataJson": "{\"start\":3547,\"end\":3580}"}, {"text": "The server has a key value map. This is nothing else than a regular go map. And let me see, actually the key value struct declared it somewhere. Oh sorry, it was right above it. So there's a struct called KV that actually has a mutex and a map in it.", "metadataJson": "{\"start\":3580,\"end\":3605}"}, {"text": "And the map is like where we're going to do the put and get operations on. And there's a lot of little preamble that you need to sort of write to sort of set up a server. But here it is, you basically allocate a new server object and then this is the key operation. RPC register. KV will register basically all the methods that are implemented on the KV struct with the RPC server with one twist.", "metadataJson": "{\"start\":3605,\"end\":3636}"}, {"text": "The method only the capital named, only the methods with the capital will actually be reported. And so basically go uses capital domains to indicate public methods. And a method with small caps is in private method. So only basically RPC register exports only capitalized methods. So for example, here's a method below, here's our get method.", "metadataJson": "{\"start\":3636,\"end\":3665}"}, {"text": "It has a capital letter, and by calling register that method is now callable by a client that connects to the server. So the server internally basically creates a TCP connection and waits on the TCP connection to get a request or a new connection request for a TCP connection. And then calls RPC servecom to serve that TCP connection. And basically every message that comes in over that connection, it will automatically find the right method that is associated with the message and call that method with the unmarshalled arguments and marshalled reply. So for example, if the client calls get connects to it, double call makes this connection into existence.", "metadataJson": "{\"start\":3665,\"end\":3711}"}, {"text": "And then if the client calls call with get, then this get function will be run. As you can see in the get function, first thing it does, it actually takes a walkout because multiple clients could be calling the server. And so there will be multiple go routines running at the same time, perhaps invoking get and put, and so they will be manipulating the map concurrently. And so we need to make sure that, you know, those that is done in an atomic way. And so therefore we use locks.", "metadataJson": "{\"start\":3711,\"end\":3740}"}, {"text": "So the get function looks at the key into the map, looks the key, looks at the key in the map and returns basically the value. If there's no entry in the map, it will return error, no key, otherwise it will return the appropriate value and that's it. And so on the server side, when this get function returns, it will marshal its response, send the response back to the client, the client will side of it will un marshal it and actually return it to the caller.", "metadataJson": "{\"start\":3742,\"end\":3770}"}, {"text": "Does that make sense? So that's sort of dirt simple. Key value, server in action.", "metadataJson": "{\"start\":3773,\"end\":3780}"}, {"text": "Okay, now I want to make one more point, which is an important point, and that in the end what's important to think about is what the RPC semantics are and their failures.", "metadataJson": "{\"start\":3788,\"end\":3800}"}, {"text": "So there are different types of semantics possible. Something is called at least once and this all has to do with like what does the client do if the server fails? So let's say the client sends the request, the server crashes.", "metadataJson": "{\"start\":3811,\"end\":3826}"}, {"text": "Of course. Now at some point the client will time out and it just doesn't know whether the operation actually happened or not happened. And at least once RPC semantics means that the client will automatically retry and will keep going until it has executed at least once.", "metadataJson": "{\"start\":3828,\"end\":3843}"}, {"text": "The downside of course of at least once is that the same operation might be executed multiple times. So example, if you do a put, the put might be actually executed multiple times in at least once RPC system. So that's not appropriate for many applications. So another type of semantics that's common in RPC systems is at most once.", "metadataJson": "{\"start\":3846,\"end\":3864}"}, {"text": "So the corresponding server request actually executed either zero times or once, but no more than once. And the way that is typically implemented is by filtering duplicates. And you will actually be doing that in, in later labs. Could be the case that actually both requests actually come through. Maybe the network version is temporary petitioned, and the server actually gets both requests.", "metadataJson": "{\"start\":3867,\"end\":3893}"}, {"text": "The server has to arrange that it detects a recent request and doesn't execute it twice. Now of course, ideally you might actually want exactly once because that's actually what the normal procedure call would be do. Like if you call a procedure in your server, in a normal sequential program, it actually executes exactly once. It's never possible to be at least once or at most once. This turns out to be actually very hard to arrange.", "metadataJson": "{\"start\":3894,\"end\":3919}"}, {"text": "This requires you basically have to maintain state on disk, and so that tends to be expensive. And in fact, in practice, very few RPC systems are exactly ones. Although in the labs you're going to build XD one, in lab three, you can actually build an RPC system that's basically exactly once. Okay, in practice, go RPC system is at most once. So if you do a call and you do the call across the TCP channel, the TCP channel will make sure that there are no duplicates and the RPC system will either execute once or none at all, and then in the case and return an error.", "metadataJson": "{\"start\":3920,\"end\":3960}"}, {"text": "And then of course the application may retry, but now it's the application responsibility to deal with the problems of duplication and failed messages. Okay, so here's the sort of the key point, correct? The fact that there are failures basically makes your rpcs not identical to procedure calls. So even though that the goal is to make them look as similar as possible, they're actually not identical. And really the thing that exposes that difference is, is the failures of the surface crashing.", "metadataJson": "{\"start\":3961,\"end\":3992}"}, {"text": "Any quick questions about this quick intro for RPC?", "metadataJson": "{\"start\":3995,\"end\":3999}"}, {"text": "If not, then I want to stop the lecture here so that people that need to go, or students that need to go to the next class, they can go to the next class. I'll be hanging around, so if there's any more questions, I'll be happy to to enter them and I'll stick around for a little while. In the meantime, enjoy lab one and good luck with it.", "metadataJson": "{\"start\":4007,\"end\":4025}"}]}
{"documentId": "lecture9", "section": [{"text": "Thank you. Okay, good afternoon or good morning, good evening, good night, wherever you are. So today I want to talk about zookeeper. And with the background, the paper that we just signed for today, which is from 2010, and so this is going to be, we're going back in the last couple lectures, I think we dove in quite a bit of detail into draft, including sort of looking at code. The lectures from now on are going to be more conceptual and exploring ideas in distributed systems through papers.", "metadataJson": "{\"start\":0,\"end\":38}"}, {"text": "And the zookeeper one is particularly relevant to us because it has a little bit of a relationship, as we'll see with lab three. So it will allow us to talk about a little bit of some properties of lab three in particularly linearizability. But the zookeeper system, more importantly is interesting because one, it's a widely used system in practice, well beyond Apache, well beyond yahoo. It is an open source Apache project that is still active. And what particularly was interesting about it for us in this lecture today, it's actually high performance.", "metadataJson": "{\"start\":39,\"end\":84}"}, {"text": "And with high performance, I mean much higher performance than what actually lab three is going to be. And we'll talk a little, talk quite a bit of detail about this. And there's sort of two reasons why it is high performance. One, declined operations are asynchronous.", "metadataJson": "{\"start\":84,\"end\":102}"}, {"text": "And really what high performs here means is that we can, the system can process many more operations per second. So it's really a throughput metric. And the second reason, you know, it's high performance is because it doesn't provide strong consistency. So it doesn't has an interesting consistency definition and it gives us some freedom to execute basically read operations on any replica and therefore read conforms can scale. Then the second aspect that is interesting from zookeeper is in addition to being high performance, it is sort of a generic, what they call a coordination servers.", "metadataJson": "{\"start\":107,\"end\":148}"}, {"text": "The point being here is that there are many applications where you need to keep track of who is part of this cluster and who is the master. So think about the Mapreduce or think about the gFs. The master in GFS it needs to keep track, or like for every chunk, who are the servers that actually serve, that cannot serve the chunk from whom the servers actually is the master. And so tracking that sort of configuration information comes up in lots of distributed applications. And Zookeeper is really designed to support that kind of thing.", "metadataJson": "{\"start\":155,\"end\":189}"}, {"text": "So you can just sort of outsource all the configuration management to zookeeper and then focus the, the rest of your application development on other aspects of your distributed system. Okay, so that's sort of a brief introduction. The topics that we're going to be talking about. And as usual, feel free to interrupt at any time or post something in the chat message. Let me actually pull up the chat.", "metadataJson": "{\"start\":189,\"end\":219}"}, {"text": "Okay, good. So just to start from the basics, Zookeeper is a replicated state machine in the same way that the replicate state machines that we've been seeing. And so let's just draw the usual picture. We have some surface. In this case, it's going to be zookeeper Ck.", "metadataJson": "{\"start\":220,\"end\":250}"}, {"text": "It receives requests from clients, say create, create a Z node. And basically the way it interacts to distribute these operations, it has sort of a separate library. Think about this as the raft library, but in their case, it's called zap.", "metadataJson": "{\"start\":252,\"end\":272}"}, {"text": "Basically, the leader sticks the operation into the equivalent of the raft library, talks to other libraries, on other peers, that basically creates a log that contains all these operations and all these machines. And then the operations are of the log of feedback to the, in our case, it would be the apply channel to the service. The service applies the operation response to the client. And so we have basically the version of this running. And so far in the labs we've been focusing mostly lab two is all about this part implementing, in our case, raft.", "metadataJson": "{\"start\":274,\"end\":323}"}, {"text": "So instead of zap, and for the first order at a very high level, you can think about Zap just being another raft providing similar guarantees. Although implemented quite differently, it provides an order of all the operations despite failures, network petitions, et cetera, et cetera, doesn't suffer from split drain. All the things that we associate with the raft library, what we're going to be focusing in lab three on, is actually implementing a service on top of it. This paper talks about this coordination servicekeeper we're going to actually implement in key value stores.", "metadataJson": "{\"start\":323,\"end\":366}"}, {"text": "And the data structure is just a map from keys to values. And so the operations that we're going to be supporting are put and get. So the client submits put and get operations to the service. The server runs them through raft and then applies them one by one to the key value store. And in zookeepers, you know, the structures are slightly different.", "metadataJson": "{\"start\":372,\"end\":395}"}, {"text": "You know, there's just a tree of z nodes. But the basic operation is the plan is the same. You know, the lower layer, the lap or the zap library or the raft library orders all the operations. They're applied in the same order on all replicas. Because they're applied all in the same order.", "metadataJson": "{\"start\":395,\"end\":411}"}, {"text": "There's no non determinism. The resulting state on each of the replicas is going to be identical.", "metadataJson": "{\"start\":411,\"end\":417}"}, {"text": "Okay, that's sort of the basic setting of this paper and sort of also the relation part of the relationship between lab three and the zookeeper service itself. I'm mostly going to be talking in this lecture on focus on the zookeeper part itself and not talk about zap, because this is going to assume that's sort of similar to what we're doing in what we're doing in lab two.", "metadataJson": "{\"start\":420,\"end\":446}"}, {"text": "Okay, I want to talk a little bit about what kind of performance would you observe if you want to finish lab three and would measure how many Putin gets. Your operation can get through per second, because one of the achievements of this paper is this high performance. So let's think a little bit about that. So let's assume there's a put operation coming in, and, you know, put operation comes in by the leader. And so we're just going to go for the normal case, like the standard case where everything is working.", "metadataJson": "{\"start\":448,\"end\":479}"}, {"text": "No network failures, no partitions, nothing. Everything works out perfectly. Here's the leader. You know, we got two followers.", "metadataJson": "{\"start\":480,\"end\":486}"}, {"text": "And, you know, you know, that protocol, you know, probably inside out. You know, the first thing, of course, that happens, like you would call the leader called start. Start actually writes the put operation to its. To the log in the leader, and then the leader propagates its log to the other followers. And we saw before that actually happens in parallel.", "metadataJson": "{\"start\":489,\"end\":514}"}, {"text": "Let me draw this slightly differently.", "metadataJson": "{\"start\":515,\"end\":517}"}, {"text": "Basically launches a bunch of RPCs almost instantaneously to the different followers. Each follower, of course, will append the entry to its log. So that requires a write to persist in storage. Same thing here. And then the response back.", "metadataJson": "{\"start\":519,\"end\":536}"}, {"text": "And so here is the response back. And in this case, if a majority has responded, the leader can actually apply the operation. So the leader will actually apply the operation here. Sorry, let me not indicate. So do the put and send the response back to the client.", "metadataJson": "{\"start\":537,\"end\":554}"}, {"text": "So what we're curious about is, like, how many puts per second can we actually get in this setting? And we think about it when you. Gross, gross. Back to the envelope calculation. We don't really care exactly about the exact numbers, but one round trip, we need at least one round trip to actually get the majority.", "metadataJson": "{\"start\":555,\"end\":581}"}, {"text": "The leader needs to talk to at least one follower to actually maintain the majority. So we're going to have at least one round trip messaging, and then we sort of need to look at the rights to stable storage because those tend to be expensive. And we'll see, in this case, we're going to have two rights. There's going to be one right at the leaders, one right at the follower. At that point, we have at least two nodes that have a copy.", "metadataJson": "{\"start\":581,\"end\":608}"}, {"text": "So the thing will be committed if no further failures. And so basically, at minimum, we're going to need two writes. So that's sort of the base and the best you could do, at least in this or the simple scheme that we discussed here, and sort of we can think about like what the cost is. And in a round trip, you know, maybe it was running in the data center, networks were not across the Internet, you know, maybe, you know, that actually comes down to one millisecond.", "metadataJson": "{\"start\":608,\"end\":637}"}, {"text": "We're roughly in the neighborhood of a millisecond, maybe a little bit faster, but we really care about it, as we'll see in a second. So we're going to do two writes to stable storage, and writes actually to stable storage tend to be expensive. And, you know, it depends on orders, like what medium or what technology you're using for stable storage. Let's assume like we're using SSD's, you know, sort of pretty typical. And then, you know, presumably one write is in the order of, you know, maybe two milliseconds.", "metadataJson": "{\"start\":640,\"end\":663}"}, {"text": "You know, we got to really make sure actually the write ends up on the, in the SSD. So it probably has to be asynchronous write. So it means like two milliseconds for one write, you know, so two writes would be roughly, you know, four milliseconds. So we add it up, you know, that's going to be five milliseconds.", "metadataJson": "{\"start\":663,\"end\":682}"}, {"text": "And so how many operations per second just to see if anybody's still awake?", "metadataJson": "{\"start\":684,\"end\":689}"}, {"text": "200. Yeah. So that's going to be 200 puts per second.", "metadataJson": "{\"start\":693,\"end\":697}"}, {"text": "Any questions about this? Does that make sense?", "metadataJson": "{\"start\":700,\"end\":703}"}, {"text": "Okay, so now let's look at Zookeeper. What's the round trip for in the rights. I'm sorry, I missed it.", "metadataJson": "{\"start\":706,\"end\":712}"}, {"text": "The right, there's no round trip. There's one round trip, correct. To talk from the leader to the follower and the two rights, one at the stable storage, the leader and one at the stable storage of the follower. And the two rights add up to four, the round trip, to roughly one millisecond. So the total is five milliseconds for one put.", "metadataJson": "{\"start\":715,\"end\":734}"}, {"text": "Okay, let's look at zookeeper again. The metric that the paper is interested in is the throughput metric, where basically declines. You have many, many, many clients and they pump many requests to shookeeper as much as possible and pipeline them aggressively. So let's see what the results of that is. And so let me pull up the graph out of the paper and, you know, look at that paper.", "metadataJson": "{\"start\":737,\"end\":786}"}, {"text": "The graph a little bit. So a couple things to presumably to observe, you know, on the x axis is the percentage of read requests, as we'll see in a second. You know, this is going to be important to distinguish read from write operations. And so write operations are really operations that modify any write operation that modifies the state. And read operations are operations that don't modify the state at all.", "metadataJson": "{\"start\":786,\"end\":809}"}, {"text": "So in our lab, three terms put would be in the write operation and get the read operation. And on the y axis is the number of operations per second. And let's look at the case of free servers. And so the first thing you notice is that at zero reads, so only write operations. So the ones that are modified state, you know, we get, you know, roughly 21,000 operations per second as throughput.", "metadataJson": "{\"start\":809,\"end\":837}"}, {"text": "All right? And you know, we look at, you know, if the system only has reads, it actually gets a lot more, you know, it gets up in the, you know, whatever the 60 70 region. And in fact, what really was going on is that the number of reads or the throughput in terms of read just scales with the number of servers.", "metadataJson": "{\"start\":838,\"end\":858}"}, {"text": "So if you have three servers, you get three times the read performers of one server. If you have five servers, you get five times the read performance of one server. That's of course not true with writes. Correct. In fact, if you look at this graph, you see that if with more servers, the write performance actually goes down.", "metadataJson": "{\"start\":865,\"end\":886}"}, {"text": "And the reason for that is presumably the leader has to chat with more servers to actually get operation through. And so when we're purely doing write operations, we're actually limited and we cannot get expect more performs than a single server. And in fact, that the app servers are going to go down in performance. And so this 21,000 /second even for a single, for write operations with a configuration of free servers is an impressive number that's quite a bit higher than actually the simple calculations that we did for lab free. Lab free will never get in, that will not get close in the neighborhood at all.", "metadataJson": "{\"start\":886,\"end\":928}"}, {"text": "We want to understand, we want to see in this design, what did the designers do to actually get that kind of performance.", "metadataJson": "{\"start\":930,\"end\":936}"}, {"text": "And so there are two, as I mentioned earlier, there's two key ideas. One, everything is asynchronous, where the clients can submit many operations to raft or zookeeper in a single shot. So they're all pipelines. So basically when the way to think about it, the zookeeper client basically says, please start executing this put and doesn't wait in the response of the put. It just immediately issues the second put and then the third and the fourth and the fifth.", "metadataJson": "{\"start\":941,\"end\":972}"}, {"text": "And so for example, a lot of these puts run will be batched all together, maybe even in a single message, all be transferred to the leader and the leader will apply them all at the same time. And in fact we'll write to the persistent storage only once for this whole batch of operations. So instead of having one write per operation, you're going to have one disk write for many, many, many operations. And this is one reason they get this very good performance on write operations. And then the second thing is they do something special for read operations.", "metadataJson": "{\"start\":972,\"end\":1007}"}, {"text": "They allow read operations to be processed by any server.", "metadataJson": "{\"start\":1007,\"end\":1012}"}, {"text": "So instead of running all the operations through the leader, they allow operations to actually be processed by any server. So the latter, I want to talk a little bit more about it and I think, I wanted to think about could we do something similar? Like let's say we want to do lab three and we're going to do the same trick. We want to look at basically reads from any machine or any peer. I guess it's there.", "metadataJson": "{\"start\":1017,\"end\":1053}"}, {"text": "So the picture would be as follows. We have a leader, we have the two followers. We just stick to the case of three and we have a client. And we're going to consider what actually could happen if, you know, we sort of naively follow this strategy where we're going to read from anything. So here's our client, the leaders.", "metadataJson": "{\"start\":1056,\"end\":1081}"}, {"text": "Actually, you know, when we do puts, you know, they all go for the leader. And so the client, you know, basically does a read. And let's say, you know, this was a put was done and at the same time, or roughly after, after the put was done, the client issues again and it talks to one of the followers, an arbitrary one, let's say for this case it does not talk to the leader and then the follower response. And the question is what value does the get observe.", "metadataJson": "{\"start\":1081,\"end\":1113}"}, {"text": "So what's the possible values that the get can observe? Now let's say that we're reading whatever the key x and that initial the value of x is zero. And this put actually put x to one. And what are the values that get connection return if we don't do anything particularly special?", "metadataJson": "{\"start\":1115,\"end\":1133}"}, {"text": "So just a question here about the setup. So if we're assuming that draft is the infrastructure here and get is just another command, then wouldn't the follower just redirect the client to the leader to put the get request for the leader? No, no. So the goal is correct. We could do that.", "metadataJson": "{\"start\":1136,\"end\":1152}"}, {"text": "There's a lot of things we could do, but like we want to get this perfect scalability. So to get perfect scalability, the follower cannot talk to the leader for read operations. So basically read operations are executed by the individual followers immediately without no communication because that's the way we're going to get perfect scalability. Oh, I see. So they're not even communicating with.", "metadataJson": "{\"start\":1152,\"end\":1173}"}, {"text": "Yeah, I'm just doing the neve plan like I said, like our goal is to get perfect scalability like zookeeper does. And we want to understand like, you know, is that difficult or easy or what does that really mean? And so the first thought experiment is like, we do absolutely nothing at the leaders, the followers, the followers get the read operation executed and return the value. Awesome, thanks. And what, the question is what values can be returned by the, can the client observe in this picture?", "metadataJson": "{\"start\":1173,\"end\":1201}"}, {"text": "It can be either because maybe they make it through the desk of the leader yet. Yeah. So it could be. So neither can return zero or it could return one. So it can return stale data is a possibility.", "metadataJson": "{\"start\":1201,\"end\":1218}"}, {"text": "Let's say it returns one. So this get returns one just for a fault experiment, and then the client does another get.", "metadataJson": "{\"start\":1222,\"end\":1231}"}, {"text": "I'm not going to really say to where that get is going, but what values could we see in response to that gap? Assuming there are no other rights, it should be a one, right? Yeah, unfortunately, because I have three servers. If I had five servers, why is it different? Okay, let's make it different.", "metadataJson": "{\"start\":1233,\"end\":1265}"}, {"text": "So certainly it can return one. Correct. That we agree on that. Because if the follower talks to the second get request talks to a follower that actually has seen the put operation, which the majority of them have seen the put operation, we're going to get a one back. Correct.", "metadataJson": "{\"start\":1267,\"end\":1285}"}, {"text": "And the real question is, could it see a zero even though it observed the one earlier? I mean, it could see a zero even in the case of three servers. Right? Because let's say that you have the majority of servers. Okay, let me, let me do first the five case because it's simpler to see, are we assuming that the client always asks the same peer or.", "metadataJson": "{\"start\":1285,\"end\":1311}"}, {"text": "No, there might be a little network petition or disconnection for a brief period of time. So, you know, not doesn't have to talk to the same peers last time, correct? Yeah. So in that case it can talk to a different peer and that peer may respond with zero. And that's inconsistent.", "metadataJson": "{\"start\":1311,\"end\":1327}"}, {"text": "Exactly. So this is possible. So we're going to have to sort of strange behavior. Correct. In this configuration where you might see a recent, in the first case we might see actually a recent value and then we read actually something from back in time.", "metadataJson": "{\"start\":1328,\"end\":1342}"}, {"text": "Yeah. So if we do nothing special and naively read from any peer, then, you know, we have sort of two citation problems. I mean, the get can return stale data and the get can return data even from back in time. And so, sorry, wasn't this possible also with three followers, because the majority was the leader and one follower, and you could ask the other one if you've seen the one. Yes, it could be possible.", "metadataJson": "{\"start\":1348,\"end\":1379}"}, {"text": "Absolutely. The three would be possible too. I think with five issues, much more clear that this is possible.", "metadataJson": "{\"start\":1380,\"end\":1384}"}, {"text": "Okay, so then we're going to go back and sort of think about a little bit of this behavior. Correct. Returning those values. Is that okay? And this is sort of an interesting question, and it depends, of course, like what you mean with correctness and what, you know, if something is okay.", "metadataJson": "{\"start\":1389,\"end\":1408}"}, {"text": "It depends, like what our correctness definition is and the correctness definition that we sort of been peddling, you know, for the last couple lectures, or like since the beginning of the term is this notion of linearizability, and roughly what that means. We talked a little bit about it in a week ago. It behaves like sort of a single machine.", "metadataJson": "{\"start\":1408,\"end\":1435}"}, {"text": "That's the intuition that we've been using since the beginning of the semester. But the definition of linearizability is a little bit more precise and tries to nail down what it means to behave like a single machine. And so when something behaves like a single machine, first of all, it has to be the case that even if the operation executes concurrently, you can sort of order them in a total order. So it's possible to construct the total order of all the operations, because in the end it's a single machine, so it behaves as a single machine. There's only one machine, sort of virtual machine, that can actually perform the operation.", "metadataJson": "{\"start\":1437,\"end\":1473}"}, {"text": "So total order of ops. And there has to be some properties true about that total order. And so one property that has to be true is that the order matches real time and with real time. Really what I mean is that if an operation completed before another one started, then that first operation has to go before the second operation in the total order. Then there's a third property that the read operation read off returns value of last write.", "metadataJson": "{\"start\":1473,\"end\":1516}"}, {"text": "And that's sort of the official definition of linearizability. And you can just think about this as sort of a more precise, definite, more precise statement of this first thing, this intuition, namely the whole thing, behaves like a single machine. Now we want to go back and think a little bit about the scenarios that we have just on this whiteboard namely these two cases of stale data and back in time. Think whether linearized reliability allows that.", "metadataJson": "{\"start\":1523,\"end\":1552}"}, {"text": "Let's first focus on the first one. So we have a client one. The way you would draw this out and reason about linearizability is you draw diagrams of this form where the left bar is the start of the operation, the right bar is the acknowledgement to the client that the operation has been executed. And in this case, we're sort of saying, where's the put to x? And that put the value one.", "metadataJson": "{\"start\":1554,\"end\":1577}"}, {"text": "Then we had another client, or the same client. Let's do it. Draw another client that basically did a read, and the read started well past the put operation. So this was a get of x. And we had one case where the get of x actually returned to zero.", "metadataJson": "{\"start\":1578,\"end\":1595}"}, {"text": "That was the first possibility. And so that's what actually happened on the previous board. And now we want to sort of think about this. Is this execution allowed by linearizability, where this is the correctness definition that we're looking for? And we want to see this execution, this order of operations that happened in practice, at least we have seen that it's possible in practice.", "metadataJson": "{\"start\":1596,\"end\":1618}"}, {"text": "Is this allowed by linearizability? And that is our correctness criteria. N. Is this aligned by linearizability?", "metadataJson": "{\"start\":1618,\"end\":1626}"}, {"text": "No. No? Why not? Well, because the c two client operation started after the c one completed. So in the total order, you have to have put x one and get x.", "metadataJson": "{\"start\":1631,\"end\":1644}"}, {"text": "And it should be one because it should read the last break. Yeah. So basically, in the total order that you construct this guy, this operation must be after that operation because it started later. But then you look, that violates rule number three, correct? That an operation returns the value of the last.", "metadataJson": "{\"start\":1644,\"end\":1662}"}, {"text": "Right. That's actually not the case. It actually returns near earlier value. So this is not linearizable.", "metadataJson": "{\"start\":1662,\"end\":1667}"}, {"text": "Does that make sense?", "metadataJson": "{\"start\":1669,\"end\":1670}"}, {"text": "And of course, this totally matches our intuition. Right. Because this is in a single machine. This could not have happened. You know, you wrote a value to, you know, single machine, and then you read it back and it's certainly another value.", "metadataJson": "{\"start\":1672,\"end\":1682}"}, {"text": "It's actually previous value. So there's not a lot. Okay, let's do a second one, like our other example. So we had a client one. Again, just to put, I'm going to draw a little bit more compact because I don't have much space.", "metadataJson": "{\"start\":1682,\"end\":1696}"}, {"text": "And, you know, we do put, then we do. There's the read where to get, get the run turns one. So we're not in the first case, but in the second and another case. And then we have a get that returns zero and so that's the second sort of case that we looked at, correct? At this picture, you know, the back in time case.", "metadataJson": "{\"start\":1696,\"end\":1722}"}, {"text": "And again, we can ask ourselves the same question, is this allowed bilinearizability?", "metadataJson": "{\"start\":1723,\"end\":1729}"}, {"text": "No, because the read wouldn't be returning the value of the last write. Yeah, yeah. It's a pretty straightforward observation, correct? This is absolutely not the case. In fact, it's almost simpler in the first case because, like, even, you know, these operations have to be in this order.", "metadataJson": "{\"start\":1733,\"end\":1747}"}, {"text": "But, you know, that could not have happened. That would violate rule free. Right.", "metadataJson": "{\"start\":1748,\"end\":1754}"}, {"text": "Okay, good. So this gives you some intuition of what linearizability means, how you reason about it, and basically, if we don't do anything special and we do this naive scheme, if you were implementing lab three and you followed this naive scheme, then you would not pass the test, because the test assume, or our goal in lab three is actually to provide linearizability for putting gets. And so scenarios like these ones are just not allowed. Your implementation has to be in a way that these results cannot appear. Does that make sense?", "metadataJson": "{\"start\":1756,\"end\":1791}"}, {"text": "So we're going to, in lab three, we're going to shoot for linearizability. And what is one easy way of getting linearizability? How are we going to ensure that putting gets operational and linearizable?", "metadataJson": "{\"start\":1793,\"end\":1806}"}, {"text": "Well, I mean, if you do actually only use one machine, then it will be linearizable, right? Yeah. So what is the easy solution? We run all the reads through the leader. Correct.", "metadataJson": "{\"start\":1808,\"end\":1818}"}, {"text": "So basically an easy solution to get linearizability. And in fact, that's what we're going to be doing in lab three. Lab three. What we're going to be doing is reads or get operations, get ops, go through the log. So they go through raft.", "metadataJson": "{\"start\":1819,\"end\":1838}"}, {"text": "And as you observe, it seems if they really go all through one machine, well, they might not go through all one machine. The leader may change over time, but we know that the leader is always total ordered and that the log is total ordered. And so we're going to be able to construct a total order that actually has the order matches real time and all the reads to return the values at the last. Right. Because basically the raft protocol will guarantee that all the entries in log are in a total order.", "metadataJson": "{\"start\":1842,\"end\":1871}"}, {"text": "And of course, the raft protocol has to do quite a bit of work to actually make that all happen. But despite network failures, despite network splits, the raft protocol will guarantee us that basically all the operations happen in a total order. In fact, the whole replicated state machine approaches are based on this idea, correct? That like, all the ox are ops in the total order and applied in the same order on all peers. And as a result, everything looks, looks kind of like a single machine.", "metadataJson": "{\"start\":1873,\"end\":1903}"}, {"text": "And so the easy way to solve this problem is to run all the reads, you know, through the leader, whoever the leader is, at that particular point in time. And that will give us linearizability.", "metadataJson": "{\"start\":1903,\"end\":1913}"}, {"text": "Let me pause for a second. Do you have any questions about this?", "metadataJson": "{\"start\":1917,\"end\":1920}"}, {"text": "Sorry. Matches real time. It just means that if operation one ends before operation two starts, then one is before two. Yeah, that is graphed. You will see that this will happen automatically.", "metadataJson": "{\"start\":1922,\"end\":1934}"}, {"text": "Correct. Because if an operation actually completely finished, it, then must have been the case that the leader responded back to a client. And then if the client started the operation later and must end up later in the log at the leader. So this is going to be a property. That's true.", "metadataJson": "{\"start\":1935,\"end\":1952}"}, {"text": "And also just to double check and maybe reiterate. So in lab three, all of the client requests are going to be synchronous. Yes, absolutely.", "metadataJson": "{\"start\":1953,\"end\":1962}"}, {"text": "Okay, good. So one downside of this scheme, we would go back, actually, if you read the raft paper very carefully, there's an optimization for read only operations, but even that optimization requires some communication. So, like, if we just follow this naive. So this straightforward plan to actually get linearizability, does this, what does that mean for performance? We go back to sort of thinking about contrasting it to a zookeeper.", "metadataJson": "{\"start\":1964,\"end\":1994}"}, {"text": "Is, for example, the number read operations. Is it going to scale with the number of servers? No, because now everything has to pass through the leader. Yes, exactly. Everything has gone for the leader again.", "metadataJson": "{\"start\":2000,\"end\":2012}"}, {"text": "So, you know, no matter, it's a little bit undesirable. Correct. And so an interesting question is, like, you know, how is it possible that like, the zookeeper gets this great performance and like, you see that the simple scheme actually doesn't really work, or at least violates linearizability. And so, one, so we want to talk a little bit, like, to understand what does it really, how does Zoop get this? And so the first thing to really realize, and this is probably the most important part, is that zookeeper does not provide linearizability.", "metadataJson": "{\"start\":2012,\"end\":2046}"}, {"text": "It basically changes the correctness definition.", "metadataJson": "{\"start\":2048,\"end\":2051}"}, {"text": "And so the zookeeper service is not going to behave like a single machine. You know, it's going to have results that never happen on a single machine. And so the particular. So what is it? What does it provide?", "metadataJson": "{\"start\":2062,\"end\":2077}"}, {"text": "Well, it does provide linearizable writes.", "metadataJson": "{\"start\":2077,\"end\":2081}"}, {"text": "So all the operations, all the write operations actually go through the leader and go through the log and are pended to the log, every peer in the same order. And so they can also be plied in the same order. So we still have this replicated state machine approach where we apply all the right operation, all the operation to change data into total order. But there's a couple more properties. But it doesn't not provide linearizability for reads.", "metadataJson": "{\"start\":2091,\"end\":2125}"}, {"text": "Instead it sort of provides two sort of a different property, which is that all the operations appear in FIFO order, in FIFO client order. This partially has to do with the asynchrony. The client may submit multiple requests one by one without waiting for a response. And Zookeeper will guarantee that if you submit, if client one submitted a request, and then client one submitted another request, then that second request will appear later in the result, will observe the result of the first operation.", "metadataJson": "{\"start\":2125,\"end\":2167}"}, {"text": "And so in particular, writes going client order, and then reads where all the action is for where the instant properties are, the reach observe last right. Okay, so reach observe last right from same client.", "metadataJson": "{\"start\":2169,\"end\":2202}"}, {"text": "And so this sort of makes sense, you know, basically this sort of says like you read your own rights. So if you did a write operation, you immediately follow the read operation. You see at least the results of your own rights. But for writes from other operations, from other clients, the zookeeper does not guarantee that property. Instead, what it guarantees is that the read will observe some prefix of the log.", "metadataJson": "{\"start\":2210,\"end\":2237}"}, {"text": "And so this means that you can actually see stale data, as you may read from a follower, and that follower has a prefix of the log, but not the last entries in the log, because maybe this has got to lag behind a little bit. And nevertheless, that follower is allowed to return a value, because the only thing that zookeeper is going to guarantee that actually reads observe a prefix of block. So the operations can now go out of order once they in the log reads, can't read operations out of the log out of order. It really has to be a prefix of the log. And then there's a second requirement that you cannot do no reads from the past.", "metadataJson": "{\"start\":2241,\"end\":2291}"}, {"text": "And that really means, like if you saw some prefix one, and then you issue like a read saw prefix one, and then you read a second read, then that second read has to see at least prefix one plus more.", "metadataJson": "{\"start\":2298,\"end\":2311}"}, {"text": "And it might be no, you know, it might be just prefix one, but it cannot go back in time. So it cannot see a shorter prefix then prefix one. And so this basically, so if we look back at this picture, the zookeeper will allow this in certain cases, namely if the two clients are different, but it won't allow this up. This you can never have back in time. Okay, so I have a question.", "metadataJson": "{\"start\":2314,\"end\":2346}"}, {"text": "A conceptual one. So we have these two consistency guarantees, the linearizable rights and the FIFO client order. So if we ignore the second constraint for a second, and if we only focus on the first one, does the definition of linearizable rights actually make sense? Since the definition of linearizability depends on having a read operation and a write operation? Hold that thought for a second.", "metadataJson": "{\"start\":2346,\"end\":2369}"}, {"text": "Because the way they define linearizable rights is not basically the rights are a total order, but there is a relationship between the reads and the rights. So hold that far for a second. Okay, we'll come back, we'll get to that in a minute. Like one board, I want to make one board in between. Okay, sounds good.", "metadataJson": "{\"start\":2370,\"end\":2390}"}, {"text": "Okay, so let's look a little bit at how Zookeeper actually provides these guarantees. And so if you get the intuition how you could implement this, the paper is actually not very explicit about how they implement this. And sort of like, I'm going to give you sort of a roughly best guess. So there's a zookeeper client that runs on the client machine. In lab three, we call this as a clerk.", "metadataJson": "{\"start\":2392,\"end\":2424}"}, {"text": "And so this is a piece of software library, sort of that works, collaborates, you know, with the service and in keeper in the paper terminology, basically it is the thing that has the session. So when you join, when a client wants to connect with the zookeeper servers, it creates a session and connects using the session information to the leader and maintains state across the session. So we have a leader in Zookeeper, as we'll see with followers. Basically this is all similar to what we are used to from lab two. And the zoo could issues write to the leader because the writes are going to be linearizable.", "metadataJson": "{\"start\":2425,\"end\":2465}"}, {"text": "In fact, the writes basically follow exactly, roughly the same strategy as in the raft library. So there's going to be a log, and in the log all the writes are entered. So whatever, there's some slots. Let's say the leader pens this write in this particular index. So this has an index, and in the paper they refer to this index as the ZxId.", "metadataJson": "{\"start\":2465,\"end\":2490}"}, {"text": "So I think you can think about the CXID basically as the index in the log. And when the leader basically commits an entry right to the log, it returns the Zix id back to the client. And so the client maintains that state. So associated with a session is basically with CX ids, the CXID of the last write.", "metadataJson": "{\"start\":2491,\"end\":2516}"}, {"text": "Okay. And so when the client later on does a read, and the read doesn't have to go to the leader, because that was the whole goal to get more performance so maybe the read actually will go to one of the followers, but the read will be tagged with the CXID of the last write that that particular client has done. And so what does that mean? Well, let's say this follower is behind, correct? And it has two entries, but it hasn't actually observed the write yet because whatever the leader may be, committed it through this other follower.", "metadataJson": "{\"start\":2519,\"end\":2556}"}, {"text": "And what happens in this case is that this read the following won't really respond immediately. Instead it will wait until it's seen the Zxid and as soon as you've seen the Zxid, it actually will respond.", "metadataJson": "{\"start\":2557,\"end\":2572}"}, {"text": "Now of course this is going to be another client, and so maybe at some point this write will come through and maybe now the read, the client does another read. And so it hasn't seen no other Zx ads. And maybe like, let me make one more follower. Let's say there's yet another follower that actually has not observed that final write yet. Or actually let me, so there's going to be another, let's say there's a other client that sticks in some other write.", "metadataJson": "{\"start\":2576,\"end\":2607}"}, {"text": "That's the scenario I want to talk about. So there was another client that actually appended a w after the CXE. It is right here, but it was not observed that particularly. Right. You know, what we have here is we got the, we got the two slots, we got the right, but the green right hasn't really shown up at that particular follower.", "metadataJson": "{\"start\":2607,\"end\":2632}"}, {"text": "And so if the client now issues a second read and maybe that goes to the other follower, it has the same Zxid because it hasn't seen any new, that client has not issued any new writes, it will arrive there. In other words, that guy is allowed to respond immediately because it has seen the ZX ID of, has seen the last cxid of that particular client. Of course it misses some writes from other clients that already been processed by some majority of the servers, but it is not required to return that data. And so it can just return it. And so this might actually return and in stale values, but that is allowed by the definition of, you know, the shook keeper.", "metadataJson": "{\"start\":2632,\"end\":2677}"}, {"text": "Correctness guarantees. Professor, I have a question. Yeah. First I thought, I'm not sure, but I understood the client reads like the session reads were sticky. So they would like in general go to the same.", "metadataJson": "{\"start\":2677,\"end\":2694}"}, {"text": "Yeah, but you know, of course, you know, there might be a little bit of, you know, might be a quick network petition or anything like it. And so in between time, you know, the, it might have switched to another server. Okay. And then in addition, turns out the zookeeper does actually do some load balancing, so. But nevertheless it can happen.", "metadataJson": "{\"start\":2698,\"end\":2719}"}, {"text": "Correct. Right. The other thing was you said, right, always, always go to the leader.", "metadataJson": "{\"start\":2719,\"end\":2727}"}, {"text": "And then the leader responded with the Zxid. Doesn't the leader have to first reach consensus before responding in this?", "metadataJson": "{\"start\":2730,\"end\":2742}"}, {"text": "Yes, I guess so. You know, you just have to commit it because otherwise it's an uncommitted. Right. So I think the exact protocol, okay, I'm abstracting away a little bit from the details of the protocol. I'm just going to sketch how it works.", "metadataJson": "{\"start\":2745,\"end\":2760}"}, {"text": "I believe you're right. You know, that it must return, presumably after the entry action is really committed. Sorry, last thing you said, it always goes to the leader. But I think the paper described it could go to followers or go to a follower and then. Yeah, but it then ends up at the leader.", "metadataJson": "{\"start\":2761,\"end\":2779}"}, {"text": "Correct. So in the end it goes with the leader. Thanks. Yep. Just to clarify, when you say wait for Zxid on like for example, the second follower, or second, when we wait for Zxid, we're actually waiting for it to be committed.", "metadataJson": "{\"start\":2779,\"end\":2796}"}, {"text": "Right. It's not sufficient to just get it. Yeah, got it. Wait, but would, like, it would have been committed by the time it was like, like a client wouldn't get an uncommitted CXID. Correct.", "metadataJson": "{\"start\":2796,\"end\":2812}"}, {"text": "Like ever. No, yeah, but that's correct. So if you know the, okay, at this point, when the follower sees this Zxid and the writers in that particular CXId, now it must have been committed because, you know, the client could have not gotten that Zxid unless you know, that option of that Zx ID was committed.", "metadataJson": "{\"start\":2812,\"end\":2834}"}, {"text": "Thanks. Also. So when you say that from the read, you get stale data. So like the last basically arrow, but the client here in the read request, it supplied the Zxid within it. So it's as if the client knowingly exactly wanted that location in the log that had Zx id as its index.", "metadataJson": "{\"start\":2837,\"end\":2861}"}, {"text": "So didn't it knowingly just request that prefix, that specific prefix of the log? No, but it really says what this basically ZXD says. Like it basically counters going back in time. And so the ZXD says like you have as a follower, you have to return me a result that at least includes the prefix of the log. Through ZxId, you might have more, that'd be fine too, but at least through CXID.", "metadataJson": "{\"start\":2861,\"end\":2889}"}, {"text": "And this just stops that one case where you read back in time. Okay, awesome. Thanks.", "metadataJson": "{\"start\":2889,\"end\":2893}"}, {"text": "Okay, so now you might wonder. So this clearly does not provide linearizability and one reason people are excited about linearizability is because it behaves like a single machine. So it's easier to program, right? Like you do a good, you get a get, you roughly know what you're going to get, no pun intended. But here you certainly have a model, programming model that's different from a single machine.", "metadataJson": "{\"start\":2896,\"end\":2920}"}, {"text": "And so how do you program with this thing? And it turns out that basically these rules, this correctness definition that zookeeper has are basically you can think of as like they're good enough to actually do for the purpose to help programming. And so I want to talk a little bit about that.", "metadataJson": "{\"start\":2920,\"end\":2941}"}, {"text": "So the real point is that, you know, with linearizability, you know, it's pretty clear that, you know, that helps programming and writes, you know, for intuitive programs here, things are going to be slightly different and we want to understand actually if you know, things that work out well and, or whether this like just pain in the neck to program and just basically completely unusual. So let's look at one of the key examples they talked about in the paper. And the first thing I want to do is basically ignore the sync operation because like you can make every operation actually linearizable by just issuing a sync like before you do the read. But that of course makes everything very slow again and we're not going to get our performance advantage. So basically we want to avoid doing sinks.", "metadataJson": "{\"start\":2952,\"end\":2998}"}, {"text": "And so I'm just going to ignore sinks and like program as if we don't have sinks. So let's look at the following operations. So here's the write order.", "metadataJson": "{\"start\":2998,\"end\":3008}"}, {"text": "We'll do a couple operations. And this is the case of the ready file. So we issue a delete of the ready file. So for example, this is a new master that becomes the new leader. And so it needs to write a sort of configuration information in it, like who you are part of the replicated state machine and who is the leader.", "metadataJson": "{\"start\":3012,\"end\":3044}"}, {"text": "And so it writes some configuration files. So write f one, write f two. And then does the create of ready.", "metadataJson": "{\"start\":3045,\"end\":3058}"}, {"text": "And then other followers might in other read order, they can, you know, for example, call, you know, if you know exists ready.", "metadataJson": "{\"start\":3062,\"end\":3078}"}, {"text": "And so you give hash, this operation exists. And if ready exists, then it will immediately return true and otherwise not. And so you have to wait. So let's ignore that case for a second. Let's assume that the second client, so here's the one client did the write operation.", "metadataJson": "{\"start\":3082,\"end\":3103}"}, {"text": "Second client does the read operations and then a, if it exists, then the client reads f one and then read f two.", "metadataJson": "{\"start\":3103,\"end\":3111}"}, {"text": "And so the thing that we, you know, we want to understand, like, you know, what values could f one this read actually returns. And I think the thing that we worry about, correct. Is it could return. Could it return some result of a. Right that was done much earlier here.", "metadataJson": "{\"start\":3115,\"end\":3140}"}, {"text": "We must have observed this. Right.", "metadataJson": "{\"start\":3145,\"end\":3147}"}, {"text": "I think the paper mentions that the reader can watch certain things and be notified of changes. Yeah. So let's assume that actually the file exists. So create actually succeeds immediately. So let's talk about the notifications in a second.", "metadataJson": "{\"start\":3153,\"end\":3167}"}, {"text": "So this exists, returns immediately. No watch is involved, it just exists. And then we do that second client does a read of f one. I think it should read whatever was written by the first client because the operations are in FIFo. Yeah.", "metadataJson": "{\"start\":3169,\"end\":3187}"}, {"text": "Right. So I think the real thing that actually if we saw this value, correct, like for some, right earlier, that would mean that we're reading back in time. Correct. And that is just not allowed. The rules actually forbid that this read must observe that value of that write.", "metadataJson": "{\"start\":3187,\"end\":3211}"}, {"text": "Because this read, the previous read, he exists observed this write. So we know that this exist id must have seen the zxid corresponding by that create. And so that means that this read will must see the last write that was performed in the total order that preceded that particular create. And so the last write in that critical order before that is this particular write, because all the writes are actually linearizable. So it must be the case that this read f one observes the result of the write f one.", "metadataJson": "{\"start\":3211,\"end\":3249}"}, {"text": "So this is nice, correct. Because if some new leader became the primary get raised configuration file, we know for sure that actually we're going to see that last configuration file that was created by that new leader.", "metadataJson": "{\"start\":3250,\"end\":3263}"}, {"text": "So we see here an example that these rules are sort of carefully chosen things that you might care about if you're writing a configuration service that actually. So they work out.", "metadataJson": "{\"start\":3265,\"end\":3275}"}, {"text": "Sorry, I might have not understood what you were saying before, but in this case, if it exists, like if it's checking exists, ready couldn't read stuff before ready was deleted.", "metadataJson": "{\"start\":3278,\"end\":3289}"}, {"text": "Okay. All the writes in a total order. So this write is in total order. That write is in total order. The create is in total order.", "metadataJson": "{\"start\":3292,\"end\":3297}"}, {"text": "So this read here on the other side has observed that create. So whatever read is going to do is going to go back in total order, correct. And like, and observe the last right? In that total order. And the last right to f one is this one.", "metadataJson": "{\"start\":3298,\"end\":3310}"}, {"text": "But it exists, right? No existence is a read, but exists. Observe this particular write. Oh, you're saying it, you cannot read it back in time, correct? That's the whole goal.", "metadataJson": "{\"start\":3310,\"end\":3321}"}, {"text": "Right. But how did we know that it, that it observe that? Exactly. I told you that. I said like the file existed, so it must be the case that it observed, it just returned.", "metadataJson": "{\"start\":3321,\"end\":3332}"}, {"text": "True, but it, but it existed before you deleted it, right? Yeah, yeah, yeah, yeah. But you know. Okay, well go back in a second. Let me.", "metadataJson": "{\"start\":3332,\"end\":3341}"}, {"text": "Okay, so this is the second case. This is a good point. Let me talk about that. So like there's another scenario and I think this is the one you're worrying about that could have happened. And this is where notifications come in.", "metadataJson": "{\"start\":3341,\"end\":3352}"}, {"text": "So at least we'll agree that this is right. Correct. So the second case, more rules. And this is indeed interesting. I think the case where you're worried about is here's our reader again.", "metadataJson": "{\"start\":3352,\"end\":3369}"}, {"text": "Here's our writer again. And the reader calls exists on ready. And let's assume the file is there and it does a read of f one almost same as in the previous scenario. And now there's some change in leadership, there's a crash recovery and all the stuff is happening. And so there's a new primary.", "metadataJson": "{\"start\":3369,\"end\":3400}"}, {"text": "It deletes ready.", "metadataJson": "{\"start\":3401,\"end\":3403}"}, {"text": "You know, it writes f one, it writes f two and it creates ready like as before.", "metadataJson": "{\"start\":3406,\"end\":3422}"}, {"text": "And let's assume that this like this reader a little bit delayed. I don't know, something else happened on the machine and you know, now it does the read of f two.", "metadataJson": "{\"start\":3425,\"end\":3433}"}, {"text": "And I think this is the very question you're sort of asking about because this seems worrisome, right? Because now there's a configuration change and if this configuration change gets slotted in the middle here. Correct. This read of f two is going to return the new configuration as opposed to the read of f one. That is going to return the old configuration.", "metadataJson": "{\"start\":3435,\"end\":3455}"}, {"text": "And clearly things are going to be messed up. That is not a scenario we want to be in. So that would be a terrible outcome. And how does that actually get rectified or how does actually zookeeper deal with this? Well, this is where the watchers come in.", "metadataJson": "{\"start\":3455,\"end\":3472}"}, {"text": "The picture that I drew in the previous board is not completely correct. In addition to calling exist with this, ready is going to say watch to true.", "metadataJson": "{\"start\":3473,\"end\":3481}"}, {"text": "And what that means is that this delete will change the ready file. And we have now set a watch on the ready file. And so when the ready file gets deleted by this new primary that actually results in a notification.", "metadataJson": "{\"start\":3489,\"end\":3507}"}, {"text": "And there's a rule for this notification. And the rule for the notification is that every notification will be delivered for writes that go after it. And so what has to be the case that this notification will be delivered before the write to f one. So when. So there's two possible scenarios.", "metadataJson": "{\"start\":3514,\"end\":3538}"}, {"text": "Correct. The notification gets delivered here or the notification gets delivered, like after the read of f two. Let me move that read of f two slightly up.", "metadataJson": "{\"start\":3538,\"end\":3549}"}, {"text": "So it's still happening sort of in time behind the write operation. But the notification gets either delivered here, depending on the delays, or it's going to deliver to here. Sorry, what's the exact wording of that rule that allows this to happen?", "metadataJson": "{\"start\":3553,\"end\":3568}"}, {"text": "Basically, I think one way to think about is a notification is almost like a write operation and the followers implement it so that if your change happens to delete, the notification goes off. That notification is delivered to the client with that zxid.", "metadataJson": "{\"start\":3571,\"end\":3587}"}, {"text": "Again, the paper's not, but I still don't understand why this guarantees that it can go like before. Wait. So the valid places for it to be are before the write of f one and also like after the write of f two. Right. The notification is delivered after the.", "metadataJson": "{\"start\":3591,\"end\":3613}"}, {"text": "After the delete of ready and before the writes. And before the writes with f one and f two are visible. Or end the create for that matter. Oh, I see, that's just a rule. Zookeeper has to guarantee that.", "metadataJson": "{\"start\":3614,\"end\":3633}"}, {"text": "Okay, okay, so that means there's two cases. Correct? Like the notification gets delivered before the read of f one or after the read of f one. If it gets delivered after the read of f one of f two. Is there a problem?", "metadataJson": "{\"start\":3633,\"end\":3648}"}, {"text": "No, no, because then the read just happened before the writes. Yeah. So everything is good. So this is if this whole block is happening, after the read of f two is perfectly fine. And how about here?", "metadataJson": "{\"start\":3650,\"end\":3660}"}, {"text": "Wait, professor, did you say the watch is like a, like write something? Well, you can think about it. The watch is not a write operation. I didn't mean to imply that. But the watch is executed with the appropriate sort of zxid that's associated with that modification.", "metadataJson": "{\"start\":3663,\"end\":3681}"}, {"text": "Those are local, right? The watches are, yeah, the watches are local. And so when they're executed, it's guaranteed, you know, that they happen at the right. When the right is observed or the client sees the CXE, the watch is propagated with the CXID to the client and make sure that they are executed. Thanks again.", "metadataJson": "{\"start\":3681,\"end\":3704}"}, {"text": "The papers are slightly vague on exactly how it's implemented, but you can imagine different scenarios. But the more important point is, like this rule is guaranteed. Okay, so what happens if the notification is delivered here?", "metadataJson": "{\"start\":3704,\"end\":3715}"}, {"text": "So the client is running. Correct. It doesn't exist. The reader won and now this notification comes in.", "metadataJson": "{\"start\":3718,\"end\":3723}"}, {"text": "Then you have to restart. Probably, yeah. You have to restart.", "metadataJson": "{\"start\":3725,\"end\":3728}"}, {"text": "Okay, so what we see here basically, is that the rules make programming definitely a little bit more difficult, but not impossible. With a little bit of careful sort of programming and understanding the rules, you can actually get the desirable results. That's probably the application wants. What happens to the read f one, though? What happens to read f one?", "metadataJson": "{\"start\":3734,\"end\":3761}"}, {"text": "Well, you start all over. Oh, including that. All right.", "metadataJson": "{\"start\":3761,\"end\":3765}"}, {"text": "Okay. As you'll see, this is a trick that shows up in those recipes quite a bit. Right. Like this idea of actually, you know, bailing out and starting over again. Okay, good.", "metadataJson": "{\"start\":3767,\"end\":3780}"}, {"text": "So hopefully that gives you a sense that for two things, there's sort of, even though one people. One reason like people like linearizability is because it's very intuitive, you know, very easy to program with because everything behaves like a single machine. But, you know, if you want fault tolerance, scalability, it's hard to get actually good performance. And so one way to get good performance is to compromise on the consistency guarantee, and in this case, you know, compromising linearizability and provide some other consistent guarantee. And as we can see, that complicates the user experience or the programmer experience.", "metadataJson": "{\"start\":3781,\"end\":3814}"}, {"text": "But these rules and zookeepers are carefully chosen, so things are going to actually work out and it's doable. So it is possible to get the right guarantees. So now, there's another aspect to this programming model that I want to talk a little bit about now that is really related to the coordination service part.", "metadataJson": "{\"start\":3814,\"end\":3835}"}, {"text": "And so the examples, you know, that you need to, you know, what does it mean to be a coordination service? One good example is probably the VM virtual machine fault tolerance paper from a little while ago that we read and that had this test and set operation.", "metadataJson": "{\"start\":3845,\"end\":3863}"}, {"text": "And the goal of the test and set operation was basically to make sure that there's no split brain, because basically two clients would run and one would win the test and set and the other one wouldn't. And as a result, the one that won the testing set could conclude that that's going to be the primary. And so that is sort of an example of a feature that a coordination service should be able to provide. And I want to, you know, just to make that a little bit more concrete, let's think about, like, what lab three, could you get that with lab free, you know, basically sort of get this tested set type thing? Well, so let's do a very simple case.", "metadataJson": "{\"start\":3867,\"end\":3909}"}, {"text": "You know, let's say we have, you know, here's our simple implementation of test and set.", "metadataJson": "{\"start\":3909,\"end\":3915}"}, {"text": "And in lab three, we only have put and get operations there's no other operations. So those are the two operations. So like how might you write this? Maybe we'll do a put to a key, let's say master, and we put my IP address in it with the IP address of the caller. And then, you know, we do get, you know, and we say if the get on master is equal to my IP address, then, you know, act as master or act as leader.", "metadataJson": "{\"start\":3917,\"end\":3959}"}, {"text": "Actually, this is our, you know, neve implementation. You know, we don't have many other choices because we only have to put, we only have a put and a get and this is how we're going to implement this. Will this do the desirable thing?", "metadataJson": "{\"start\":3962,\"end\":3975}"}, {"text": "Oh, there's no atomicity between the put and the get. So maybe someone has changed it. Correct. So basically there could be two clients. Correct.", "metadataJson": "{\"start\":3983,\"end\":3991}"}, {"text": "They both could execute both puts at the same time and then observe roughly, they do it at the same time and they interleave correctly in. Both will actually return get with their particular ip address. So we can get two liters.", "metadataJson": "{\"start\":3991,\"end\":4013}"}, {"text": "And that's of course not what we want. So the main point of this example is there's basically you just have put in get. It's going to be very hard to actually implement a testing set. It turns out it's possible, but it's very complex. Use Baker's algorithm, you can basically probably do it, but it'd be ridiculous to do that in a distributed system.", "metadataJson": "{\"start\":4017,\"end\":4036}"}, {"text": "And so what zookeeper does, it just provides some additional help to build these type of primitives. And we'll see you in a second.", "metadataJson": "{\"start\":4037,\"end\":4048}"}, {"text": "The other thing that presumably what you want to know, and that lab three does not provide any support for, if you're sort of a configuration service or a coordination service, is that you want to know when somebody goes down. For example, you want to observe that if the leader goes down, other parties would like to know is the leader down so that you could choose a new one if you needed to, at least on the applications building using that service. Okay, so there's two things that we really want. One is we want some way of trying to get this automaticity. That's what we're looking for in the zookeeper design and then in zookeeper design.", "metadataJson": "{\"start\":4050,\"end\":4088}"}, {"text": "Second, we're looking for in the Zookeeper design is for an application to learn whether some node goes down. So let's look at the zookeeper API. And really what we want to look at is the Znode API.", "metadataJson": "{\"start\":4088,\"end\":4102}"}, {"text": "And you'll see again that is actually carefully designed to actually make it possible to do the things that we're looking for. Okay, so the way the system is organized is, you know, there are a tree of z nodes. Typically, you know, there's like one sort of app, one has a z node that might have some children that correspond to the machines that are part of f one. So peer or machine one, machine two, like maybe the IRP addresses or DNS names, machine three. And they might actually have version numbers associated or sequence numbers with them.", "metadataJson": "{\"start\":4107,\"end\":4146}"}, {"text": "And basically z nodes can be of three types. One, they can be regular, so then they're fault tolerant, replicated and all that kind of stuff. And then they can be ephemeral.", "metadataJson": "{\"start\":4146,\"end\":4158}"}, {"text": "And ephemeral basically means that the node will disappear automatically when the session with that machine three goes away. So either because there's a network mutation, there's no heartbeats motor coming in from machine three, but at some point zookeeper decides that session is gone. And so then it will delete that node automatically. So that's for ephemeral nodes. And then there's a third one, which is the sequential, and the third one, you type of nodes are sequential nodes.", "metadataJson": "{\"start\":4161,\"end\":4199}"}, {"text": "And that really means that, you know, they have a version number associated with them in their name, and they're created, you know, one by one. In under the particular z node, all the children will have a sequence number in their name, and the nodes are not ordered by that sequence number. And so for example, this might have sequence number one, this might have sequence number two, and this might have sequence number three. And if a new one gets created, it will have a sequence number higher than three. Okay, and then there's an API associated with that that we want to talk a little bit about.", "metadataJson": "{\"start\":4199,\"end\":4234}"}, {"text": "There's create, which we already mentioned, a little bit takes a path, takes some data and flags, and the flags correspond to the free cases. And then there's delete. And in the previous slide, average little bit misleading. Delete takes a path as before, but it also takes a version number and exists takes a path and a watch.", "metadataJson": "{\"start\":4234,\"end\":4262}"}, {"text": "And then there's a get data primitive that takes a path and version number.", "metadataJson": "{\"start\":4265,\"end\":4271}"}, {"text": "And we'll see that these version numbers are the trick or the key to actually get our automaticity. And then there's set data, path data and version number. And there's also a call for getchildren to get actually all the children of a particular z node, which takes a path, and I think a watch and there sink basically are sort of a cop out operation to actually ensure that everything, if you really need strong linearizability. Okay, so I want to sort of talk a little bit about like why this version number is handy. And so let's look at a particular example.", "metadataJson": "{\"start\":4274,\"end\":4317}"}, {"text": "The simplest example I can come up with is like basically implementing a counter.", "metadataJson": "{\"start\":4317,\"end\":4321}"}, {"text": "And so the way, you know, you would write the, if you write. Okay, so let me actually first give the right solution. So while, you know, true, the way you implement incremental. So this is the pseudocode for increment of this counter is, you know, you do you get xv, you know, get data up the counter, get data, you know, count, and then if set data count, oops. So it's x plus one and diversion number.", "metadataJson": "{\"start\":4327,\"end\":4378}"}, {"text": "And if that is the case, then break. Okay, so let me quickly go over this. So to get data returns the current version number and the value of the key. So, or the path. So for the file count, it returns the value and its version of that particular point when they did the read.", "metadataJson": "{\"start\":4379,\"end\":4400}"}, {"text": "And then you call and set data takes three arguments, the path update, the new value. In this case it's going to be x plus one because we want to increment the value by one and it actually passes in. Also the verdant number. And the semantics of set data is that if the version numbers are still the same, then the set data actually happens and otherwise not. So what does this protect against?", "metadataJson": "{\"start\":4400,\"end\":4426}"}, {"text": "This prevents you from interleaving the get and set, basically. Yeah. So if like two operators, two clients did get at the same time, they would read they do get at the same time, they get both back, say, you know, whatever, x is zero and version number zero. X is zero, version number zero. Then they do both a put where, like in this case, a set data.", "metadataJson": "{\"start\":4429,\"end\":4460}"}, {"text": "So the set data with, you know, whatever x is, one, version number zero. Also this guy does the same thing, set, you know, 10 and you know why. And so both going to both clients issue those two set operations. Are both set operations going to succeed?", "metadataJson": "{\"start\":4462,\"end\":4482}"}, {"text": "Well, no. Yeah. Why not? Because one of the version numbers will be wrong. Yeah, right click.", "metadataJson": "{\"start\":4490,\"end\":4498}"}, {"text": "So one of the two goes first. Why? Why does one of the two go first? Because all writes are linearizable. Yeah.", "metadataJson": "{\"start\":4498,\"end\":4505}"}, {"text": "All rights are linearizable. So they go in some total order. So, you know, we can pick one. So let's say this guy goes first or this operation goes first. So that will increase the, that will increase the value corrected one from zero to one as correctly.", "metadataJson": "{\"start\":4505,\"end\":4522}"}, {"text": "And, but that will also, and will execute because the version numbers match, right? Like the version of zero is actually what the current version number is. So the version numbers match, the increment happens, and the set data returns true. And what will happen with the second one? Well, the second one, the version numbers won't match because the version number will be increased because this previous set data operation, and therefore the second set operation will fail.", "metadataJson": "{\"start\":4522,\"end\":4545}"}, {"text": "And so then the client will loop back and try again and try to increment and try to take another shot and do an increment. Incorrect. So what happens in this case is correct, even though the two clients executed the operation concurrently. If the interleaving is bad, this piece of code will actually do the right thing. The second client will try again and as a result the end value will be two as opposed to one.", "metadataJson": "{\"start\":4545,\"end\":4574}"}, {"text": "Does that make sense?", "metadataJson": "{\"start\":4579,\"end\":4580}"}, {"text": "If you've done any sort of lock free programming in the past, then this might all look very familiar to you. And so this sort of style of lock free, basically zookeeper sort of encourages this sort of style of lock free programming.", "metadataJson": "{\"start\":4583,\"end\":4595}"}, {"text": "Okay, what I'd like to do, since I'm almost running out of time, last time I ran over time, is I'll want to talk at some point about locks, but I will do that next time, the next lecture. Now let me just sort of summarize what we've learned so far and then I'll talk a little bit more about Zookeeper in the next lecture. So in summary, so basically this is a very successful design, widely used. You can download it, it's on GitHub, you can play around with it if you wanted to. One of the things that was interesting about it, compared to all the systems that we've looked so far, it has weaker consistency, which with weaker consistency, I mean it doesn't provide linearizability.", "metadataJson": "{\"start\":4604,\"end\":4662}"}, {"text": "And you know, we're seeing that basically as a careful designed API at least we have seen some aspects of the careful design API that despite the fact that actually has weaker consistency, you can still use it. And in fact, you know, you can use it actually for pretty important applications. You can actually use zookeeper as a configuration service like it's main purpose, sort of keeping track of like who's primary, who's, who's in the, what is the set of replicas, et cetera, et cetera. And so for this sort of crucial operation of being a configuration server, that has to be correct, because otherwise we get this split brain problem. The API is carefully designed so that if you use the API correctly you still can implement this crucial application on top of it, despite the fact that actually provides weak consistency.", "metadataJson": "{\"start\":4664,\"end\":4713}"}, {"text": "And the cool part of that is that this combination of carefully designed API and the weaker consistency allows us to get zookeeper really high performance.", "metadataJson": "{\"start\":4714,\"end\":4723}"}, {"text": "And we'll see later in later lectures more of this trick of trying to weaken the consistency guarantees to actually get better performance. To get better performance or, you know, be able to continue despite network petitions.", "metadataJson": "{\"start\":4729,\"end\":4747}"}, {"text": "Okay, let me stop here and then I will resume in a little while. The next time around that we lecture, any questions? Or again, as a usual, if you have to go, you know, please feel free to let out the go. If you want to hang around and ask for more questions, please feel free to do so.", "metadataJson": "{\"start\":4749,\"end\":4769}"}, {"text": "Sorry, can you go to the slide which said the set, the unsuccessful example for this set and for the testing set, I think it's two slides back. This one, yeah. So the new design, it is able to fix that, right? Yeah. You mean like with the APIs the zookeeper provides is the version, right?", "metadataJson": "{\"start\":4782,\"end\":4816}"}, {"text": "Yeah. If you have no channel, like. Exactly. I didn't get to do that. But that was the point of the rest of the lecture is to talk about how you can implement test a set using the version numbers.", "metadataJson": "{\"start\":4816,\"end\":4826}"}, {"text": "And clearly the increments suggest you can correct, because this is basically the same sequence, right? Oh, if this is the same thing as the master. Okay. Yes. Yeah, exactly.", "metadataJson": "{\"start\":4826,\"end\":4840}"}, {"text": "Okay. Thank you so much. You're welcome. I have a question about this versioning. To prevent lock to implement lock free programming.", "metadataJson": "{\"start\":4840,\"end\":4852}"}, {"text": "Is this much more efficient than lock free programming because you still need to retry the operation again and again until it succeeds. Yeah. If testing set has a similar property. Correct. If the test failed and you wanted to become actual increment, you have to do that again.", "metadataJson": "{\"start\":4852,\"end\":4870}"}, {"text": "It's often the case in this lock free style programming that you can have these loops where you retry. If there's a lot of contention, you're going to get a lot of retry. Of course, if there's no contention, there's no retry. Typically these lock free algorithms actually are pretty careful in how they do the back off. They don't really retry immediately.", "metadataJson": "{\"start\":4870,\"end\":4889}"}, {"text": "They have some backup plan. Right. But what benefits does this give over a standard lock? Because either way, if you have a lot of contention, you're going to be sitting there and retrying a lot. Yeah.", "metadataJson": "{\"start\":4889,\"end\":4902}"}, {"text": "So the increment counter is an example where basically you sort of implicitly do the walking. Because you will see if we implement locks in Zookeeper, like using the zookeeper, if you implement locks with zookeeper API, and then if you do the stupid lock, you can also have this contention issue. Of course there's a way of implementing the smarter walk that they talked about, like without the hurting, and then you can do better. And so I'm always hoping to talk about that next time. All right.", "metadataJson": "{\"start\":4904,\"end\":4939}"}, {"text": "Thank you. I think the real point here is that you can use these primitives to actually do lock free programming with the interface that the lab three provides. It's not possible.", "metadataJson": "{\"start\":4939,\"end\":4949}"}, {"text": "Makes sense. Thank you.", "metadataJson": "{\"start\":4951,\"end\":4953}"}, {"text": "Any further questions?", "metadataJson": "{\"start\":4962,\"end\":4963}"}]}
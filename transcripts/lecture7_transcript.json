{"documentId": "lecture7", "section": [{"text": "Okay. Good afternoon. Sound check. Just double checking. People can hear me.", "metadataJson": "{\"start\":6,\"end\":14}"}, {"text": "Yeah. Yeah. Thank you. Okay, good. So good afternoon, good evening, good morning, good night, wherever you are.", "metadataJson": "{\"start\":16,\"end\":23}"}, {"text": "So we're going to talk today more about draft, and we want to cover the following different topics which are going to be relevant to labs. So first of all, I want to talk a little bit more about log divergence. We sort of had a cliffhanger at the end of last lecture where we got in a discussion of figure six. I want to resume that discussion. I want to talk about log catch up and what happens if.", "metadataJson": "{\"start\":24,\"end\":50}"}, {"text": "How do followers catch up then a little bit of a persistence, like what state must be, what state in raft actually must be persistent in storage, which is going to be really relevant for two c. And also talk about related to that to snapshots. Yeah. If there's any questions, please feel to ask. And then finally, I want to talk about linearizability, a correctness criterion that comes up quite often and is in the paper, used also in a bunch of places.", "metadataJson": "{\"start\":52,\"end\":87}"}, {"text": "And this will allow us to talk a little bit again about, like, how does a service use raft? So those are the topics I plan to talk about. If any questions right now, please feel free to ask. And of course, always jump in at any point.", "metadataJson": "{\"start\":87,\"end\":102}"}, {"text": "Okay, so we saw, last week we started talking about draft. We saw that the leader has sort of this job of replicating its log onto the followers. But due to crashes and leader election, the state of the system, the logs can actually quite diverse quite a bit. And figure six is an illustration how that could happen. The leaders can go down, they may append some more entries.", "metadataJson": "{\"start\":107,\"end\":141}"}, {"text": "And so there's a whole bunch of different scenarios where a system can end up in. And so the figure six or figure seven actually shows a bunch of those.", "metadataJson": "{\"start\":141,\"end\":152}"}, {"text": "And the main reason for for that figure is that it actually sharpens up the leader election rule.", "metadataJson": "{\"start\":154,\"end\":162}"}, {"text": "So once the leader goes down and we need to elect a new leader, there's actually some restrictions that must be applied to actually make sure that we can actually converge on the right log in the end. And so first of all, one part of that is that any leader needs to achieve a majority. This is part of the idea to actually avoid this brain split syndrome, or split brain syndrome, so that we can actually make sure that in any two subsequent elections, there's going to be at least one node that participated in both majorities, because two majorities must overlap and that node must actually have the operations from the recent term. The majority is important, but turns out it's actually a little bit more subtle, you might think that the longest log, that should be sufficient, because the longest log has. Must have most information.", "metadataJson": "{\"start\":169,\"end\":229}"}, {"text": "So we just picked out as the next leader, and then we're in good shape. That turns out to be not the case.", "metadataJson": "{\"start\":230,\"end\":236}"}, {"text": "And the leader rule is a little bit more subtle. Put plot. Plus, at least as of date, least up to date.", "metadataJson": "{\"start\":240,\"end\":251}"}, {"text": "So the leader election is running a followers. Like, if the candidate is starting to run a leader election approaches a bunch of followers, and then the followers respond with a positive vote if the candidate actually is at least as up to date as they are. And what that means is that the last log entry must actually have the same term. Or if they actually have the same term, the longest one sort of wins.", "metadataJson": "{\"start\":255,\"end\":290}"}, {"text": "So that's the leader election rule. And we looked at this problem last week as part of the homework. What happens if, you know, this node, you know, that was. Was about to be the leader actually is dead. It's gone, you know, and who could become leaders?", "metadataJson": "{\"start\":293,\"end\":308}"}, {"text": "And, you know, we quickly discovered that, you know, the. There's a bunch of them that cannot become leader, but then there's a potentially a number of scenarios in which some can become leaders. And so in particular, you know, we identified that a can become leader, c can become leader, and d can become leader. Lead. And so then, so this is probably the most important part of this whole discussion.", "metadataJson": "{\"start\":309,\"end\":334}"}, {"text": "Like, who can we become leader? Yeah, there's questions. Is there? Let me. Hold on.", "metadataJson": "{\"start\":334,\"end\":339}"}, {"text": "Okay, good. So who become. That's the most important part. So there's a bunch of different scenarios in which a can become a leader. There's a scenario where c become a leader, and a scenario where d become a leader.", "metadataJson": "{\"start\":343,\"end\":353}"}, {"text": "Then the discussion, folks, a little bit, are like, well, at least there's one particular scenario in which one of these can becomes leader. Other multiple scenarios in which they can be the leader. In particular, this focus. This discussion focused on a, because, like, one way that a can become a leader is when c and d are down.", "metadataJson": "{\"start\":354,\"end\":377}"}, {"text": "Right? Because c and d are down. A will talk to b, e, and f form a majority with a four. It has the most up to date log. Notice that even though f is a longer log, it actually is not the most up to date one.", "metadataJson": "{\"start\":381,\"end\":400}"}, {"text": "And so a actually will succeed in becoming the leader, and then things proceed from there. But there was an interesting question that came up. Are there other scenarios in which a can become a leader? In particular, is there a scenario where even if C and D are up or reachable or participate, is it possible that a becomes a leader.", "metadataJson": "{\"start\":401,\"end\":423}"}, {"text": "So in C and D and up. And so the question is, does C and D always vote for a? If a is the candidate? And it turns out this answer is slightly complicated, it is not completely straightforward. So if a starts this election, presumably it will start the election in term seven.", "metadataJson": "{\"start\":426,\"end\":444}"}, {"text": "And so if the context is c and d, c will be perfectly fine with that because the a is at least up to date, and so we'll be able to achieve a majority. But, you know, it is possible, correct, that D. There's one additional rule that if D actually has. If a follower has a higher term, has seen a higher term, its current term is higher than the, of the candidate, then actually can, it can stop the election because it will respond saying, like, hey, my term is higher than your high term. My current term is higher than your term.", "metadataJson": "{\"start\":447,\"end\":492}"}, {"text": "And so therefore you have to become a follower. So a will then we change back from candidate to follower and this can happen, correct, in the case of D, because D might actually have seen turn a. And we can't really tell from this picture what actually the outcome is going to be. But let's assume that, for example, you know, the. It has run once and X has increased its term to eight, maybe didn't become succeeded leader, and then its current term will be eight.", "metadataJson": "{\"start\":492,\"end\":522}"}, {"text": "And so it will vote. When a ask for its vote, d will say, no, I won't vote for you. And furthermore, my current term is a. So a will receive that message. It's higher than seven.", "metadataJson": "{\"start\":522,\"end\":534}"}, {"text": "And so a will actually step down and become just a follower. And at some point later, presumably, you know, D will run, its election timer will go off and actually it will run. And so the short story of this, you know, the morale of this is going to really, this picture is that it's absolutely possible that AC and D become leader in different types of scenarios. And that's probably the main thing to get out of this. Professor.", "metadataJson": "{\"start\":534,\"end\":560}"}, {"text": "Yeah, so I just want to ask, because I think, I'm not sure if I understood correctly, but like you said, a might be elected in term seven. Is it not true that a cannot for any reason be elected in term seven even if d was down? Right? Because people like, like d, like, already got a majority, right. In 7D, got a majority in seven because it actually was able to get something done.", "metadataJson": "{\"start\":561,\"end\":596}"}, {"text": "So presumably. Right, you're right. You know, the good observation. So it has to be the case that, you know, there's a number of people that actually already in turn seven, correct. And the picture is just incomplete.", "metadataJson": "{\"start\":596,\"end\":607}"}, {"text": "We don't really know what the current term is that people have seen so far. Yeah, right. But, yeah, I mean, the only thing is, like, I think like a majority of the servers already voted for someone in term seven, so they will. Yeah. So presumably a will go to term eight and, you know, we'll run, you know, the election for term eight, but, you know, for the same reason, d might already be in nine.", "metadataJson": "{\"start\":607,\"end\":632}"}, {"text": "Right. And so it all depends on what the current term is. What these actually these participants are in the main conclusion. Correct. The main top level conclusion is that a can they become leader?", "metadataJson": "{\"start\":632,\"end\":645}"}, {"text": "Certainly when C and D are offline, c can become a leader and D can become a leader.", "metadataJson": "{\"start\":645,\"end\":651}"}, {"text": "Thanks.", "metadataJson": "{\"start\":654,\"end\":654}"}, {"text": "Good. Okay, then let's. So we now know that the raft can sort of end in states where the logs are diverged. And so that needs to be repaired. One key component of the raft protocol is to do that, like log catch up, as they call it.", "metadataJson": "{\"start\":657,\"end\":679}"}, {"text": "So I want to talk a little bit about that.", "metadataJson": "{\"start\":681,\"end\":683}"}, {"text": "And this is basically, you know, what you sort of have to deal with in part b of the lab. And so maybe easy to illustrate with this picture. And so let's make it a little bit simple. Let's have three servers. And here's s one.", "metadataJson": "{\"start\":690,\"end\":711}"}, {"text": "It has, you know, term free in index ten is index eleven. It has no entries in ten. And 1112, 13. Here we have s two.", "metadataJson": "{\"start\":711,\"end\":726}"}, {"text": "And s two has entries, you know, three, three and five. And so this is index ten, 1112 and 1313, just to make it complete. And here is s four, sorry, s three. And let's assume we're in the scenario three, three, four and ten, 1112 and 13. And I'm not showing like the indexes before ten because they're not going to be very relevant.", "metadataJson": "{\"start\":729,\"end\":761}"}, {"text": "And let's see, there's a timeline, these different services. And just let's start out like assuming that s two becomes the leader because it has the highest. It is mostly to date, it has the highest term number in the last log entry. So it becomes leader. And now we need sort of understand how about the protocol is to synchronize these particular logs in the way this almost happens is a side effect of either the append entries because new log entries are appended, or because of heartbeats, which basically are append entries with zero new entries.", "metadataJson": "{\"start\":762,\"end\":799}"}, {"text": "So let's assume that the leader actually sends a heartbeat out. In fact, it does it correct after election, immediately sends out a heartbeat. And so it will send out a heartbeat. And the heartbeat basically has no log entries, but it also indicates two other pieces of information, namely the previous term. So the previous term, which in this case is going to be five, right?", "metadataJson": "{\"start\":799,\"end\":822}"}, {"text": "And the previous index is going to be twelve. So it sends it off to the leader. S two sends it to s three, and s three looks at this, it says like, well, let me look. You know, my previous term is actually not five, it's actually four. And so it actually sends back a message saying, no, you know, I'm alive in principle, but, you know, I cannot do Europe hint.", "metadataJson": "{\"start\":822,\"end\":852}"}, {"text": "So I'm not up to date. And so now s two has some information to actually bring it up to date. And the way it works is there's two variables that are of importance. One, for every node, s two keeps a variable, nextindex and next index. When it initializes, when it becomes leader, it is sort of an optimistic variable.", "metadataJson": "{\"start\":853,\"end\":883}"}, {"text": "It just assumes that the logs are actually up to date. And so when s two becomes the leader, it actually just sets it to 13, the same value that actually it has for itself. And that's perfectly fine because it's just a guess about what actually where s three might be and s three might be behind. And then because there's no message, the leader actually learns that. And so in fact, when they get this Dom message in the unoptimized version, so I'm going to first talk about the unoptimized version.", "metadataJson": "{\"start\":883,\"end\":918}"}, {"text": "The leader just decrements the next index by one. And so it decrements 13 to twelve. And then at some point we'll send another append entries and this time around it will actually say, okay, well, next index is twelve, I've got to send log entry five. And, you know, the previous term is going to be three and the previous index is going to be eleven. And so when s three actually receives this message, you know, it checks the previous term, it's free.", "metadataJson": "{\"start\":922,\"end\":959}"}, {"text": "The previous index is eleven. That all works out. It sees that it has the append five and so it will erase, you know, the four and stick a five in there and basically respond saying, yep, good.", "metadataJson": "{\"start\":959,\"end\":973}"}, {"text": "And so at this point the leader knows that actually the log is up to date because it got an ok message back. So then there's the second variable that plays an important role in all this, which is matchindex, which raft also maintains for the leader, also maintains for every follower. And so there's a next index for s three. There's a next index for s one and same. Learn.", "metadataJson": "{\"start\":976,\"end\":1004}"}, {"text": "There's a match index for s one, s two, s three, two. And this one is sort of, if you can think about this is pessimistic or a lower bound. So when the leader actually becomes a leader, it actually sets the value just to zero. And to indicate that basically as far as it knows, the s three doesn't really have any log entries at all. And so it hasn't delivered any log entries to the application.", "metadataJson": "{\"start\":1004,\"end\":1035}"}, {"text": "And so for s two also has to be very careful about what actually can be delivered to the application because you need to know that at least a majority of the followers actually has a copy of a particular log entry before it can deliver it. So it just starts out to be pessimistic. But then once it learns that, for example, once it learns actually that the follower is okay, we've got an okay on the append message, I can actually update the pessimistic lower bound or the match index from zero to actually 13 because it has learned that the follower is actually up to date till 13 and that the next index that is expected is 13. And at this point in time, basically it has learned from two different, it knows that particular log n is actually now replicated at least in two nodes.", "metadataJson": "{\"start\":1035,\"end\":1094}"}, {"text": "And so you might think, well, good, it has been replicated in two nodes. We can deliver it to the application because the majority clearly has it and we're in good shape. And unfortunately, that actually turned out not to be the case. It's close to true, but not completely true. And this actually has to do with figure eight.", "metadataJson": "{\"start\":1096,\"end\":1117}"}, {"text": "So I want to talk a little bit about figure eight. And the real reason what's going on here would make this slightly complicated. And you also should think it's a little bit fishy. So this leader, s two, just erased a value out of the logo of s three. And, you know, somebody put that in.", "metadataJson": "{\"start\":1118,\"end\":1135}"}, {"text": "And so, you know, erasing it, you know, it seems a little bit, you know, dangerous. And as we, so there turns out there is a corner case where you have to be a little bit careful by when you deliver, when you declare a message actually committed. And it turns out that basically figure eight illustrates that. So let me talk a little bit about this. Erasing log entries.", "metadataJson": "{\"start\":1135,\"end\":1167}"}, {"text": "And we will see is that the rule for actually when the message can be delivered to the application is slightly more subtle than just counting the replicas.", "metadataJson": "{\"start\":1171,\"end\":1184}"}, {"text": "See, actually get figure eight. Load it in. Okay, so here's figure eight. And so as usual, structure.", "metadataJson": "{\"start\":1187,\"end\":1195}"}, {"text": "Okay, let me get back to the question in the chat in a second. So here's a figure eight. And so let's walk through what the scenario here is correct. In figure a, log entry one has been committed by everybody.", "metadataJson": "{\"start\":1198,\"end\":1216}"}, {"text": "S one or s two became leader in entry. In term two, they committed or they started appending an entry. Two hasn't been committed yet because it's not on the majority for sure. Then in b, what actually happened? S five must have been disconnected.", "metadataJson": "{\"start\":1218,\"end\":1237}"}, {"text": "Hasn't heard of this. Term two became a leader in term three appended an entry to its log that certainly is not committed because there's no majority. Then we end up in c. Maybe the s five actually got disconnected again. S one becomes a leader in term four and it starts replicating this log entry to other nodes.", "metadataJson": "{\"start\":1237,\"end\":1261}"}, {"text": "In fact, it delivers, it gets back like we saw in the previous slide. It knows it's actually an s two, and it knows it actually is an s three. And it turns out that actually you might think, okay, well, one knows that actually the free nodes actually have a copy of this particular entry, and so I might be able to deliver it. And it turns out that is not true.", "metadataJson": "{\"start\":1264,\"end\":1290}"}, {"text": "There's a more subtle reasoning that needs to happen to actually commit. And namely you can only commit, you can commit after the leader has committed one entry in its own term.", "metadataJson": "{\"start\":1294,\"end\":1324}"}, {"text": "And if we think about this number two, it actually is in term, the leader is in term four. And so the commit rule wouldn't allow actually committing two immediately to the surface because that actually is one from a previous term and not from the current terminal. And so for example, your code to decide whether actually something can be delivered on the applied channel needs to take to this account. And the reason you need to take into account is illustrated by D and E. Basically what can happen is that, you know, for s one actually we might actually, in a, end up in a different situation where d actually becomes the after.", "metadataJson": "{\"start\":1329,\"end\":1377}"}, {"text": "D actually becomes the leader after, for example, s one, for example, is disconnected and it might actually start connecting. It can form a majority and actually it starts copying its particular, its entries to actually it erases the twos and actually copies its free in the entry for each term three into whatever used to be two. And this is this erasing that we talked about on the previous slide. And so we'll see, actually that even though t was on the majority of the notes, on the majority of notes, it got erased. And so the rule, and therefore the rule is as stated here, because once this is illustrated by e, once actually s three, s one commits an entry in its own term.", "metadataJson": "{\"start\":1380,\"end\":1435}"}, {"text": "And so it knows that every node there's a majority in its own term. So at this point it can actually deliver four to the application. And as a result of that, any nodes that were committed in previous terms can also be delivered to the application. So we see here that there's raising of log entries. Basically commits makes the commit rule quite slightly more complicated.", "metadataJson": "{\"start\":1436,\"end\":1460}"}, {"text": "And that's just the design decisions that the designers of raft made. They could have done it differently. They could have counted and made basically two survive if they wanted to, but they decided to go for this particular approach on the grounds that they think it's simpler.", "metadataJson": "{\"start\":1460,\"end\":1476}"}, {"text": "Okay, so this is a subtlety that will show up in the test cases for the labs. And so you have to be a little bit careful with your commit rule and that you implement it correctly.", "metadataJson": "{\"start\":1479,\"end\":1493}"}, {"text": "Okay, so, so far, you know, if we go back to this particular picture, the unoptimized version of this protocol is a little bit of a bummer, right. If you think a little bit about this, let's look at actually what happens with s one. So let's say, let me switch things. Let's say s two tries to bring s one up to date. We'll do the same thing.", "metadataJson": "{\"start\":1495,\"end\":1526}"}, {"text": "Send an append entries with nil entries, past term, previous term to be five and previous index to be twelve. It will say no, right, because it actually is at index. Index is actually a ten with term three. So it will, this guy will decrease its next index going from 13 to twelve. Then we'll do the same thing again.", "metadataJson": "{\"start\":1527,\"end\":1558}"}, {"text": "We'll send, I guess it's going to send five, the lock entry five. It will send the previous term to be three and index previous index to be eleven. It's going to get a no back, you know, then the index goes to, from twelve to eleven. And now basically it's going to work. And so what we see here, that basically for every log entry we're going to have a round trip, you know, sort of one of these append entries.", "metadataJson": "{\"start\":1559,\"end\":1585}"}, {"text": "And it turns out, you know, that can be expensive, like left. And the real question is like, you know, can a follower be far, far behind? Let me ask that, or pause there for a second so you can reflect and think about that case. Is it possible that a follower can be far, far behind for a given leader if a new machine joins the cluster? Yeah, join the cluster is a good example.", "metadataJson": "{\"start\":1585,\"end\":1615}"}, {"text": "Any other cases a machine crashed and is only coming back online after several terms. Yeah, exactly. Maybe it comes back after a day. So it might be far, far behind. So that would mean like in the protocol and the unoptimized version, that you're going to go back one by one from the log entries.", "metadataJson": "{\"start\":1615,\"end\":1632}"}, {"text": "So that's a little bit expensive. And so the paper actually discusses an optimization, so to catch up quickly.", "metadataJson": "{\"start\":1633,\"end\":1639}"}, {"text": "And, and the idea basically is, instead of like backing off, as I said earlier, the next index is basically an optimistic, it's just a guess and it doesn't really have to be that accurate. And so the observation is that we don't really have to go one by one back. It's perfectly fine, for example, to go a whole term back. And in fact, the sort of logical maybe that is going to denote, you know, it's a couple of terms back. And so we back off a couple terms and then, you know, we'll scan from there.", "metadataJson": "{\"start\":1650,\"end\":1683}"}, {"text": "So then, to illustrate a little bit how that works, let me use the following example. And I'm just going to two servers, even though there might be, you know, we need three to sort of have a majority, but let's assume there's a third one and it just plays happily along. So here's s one, here's s two, and let's see, you know, we, this guy has 55545 and this is 12345 indexes. And you know, let's say this s two has four. It's basically all sixes.", "metadataJson": "{\"start\":1684,\"end\":1727}"}, {"text": "So basically s one is, you know, quite, you know, behind. Correct. Because the only place where they actually line up is in the first entry in first, which has term four. And so in the unoptimized scheme, we would back off like one by one, one by one, until we finally got there. And to optimize this, the paper describes an optimization.", "metadataJson": "{\"start\":1727,\"end\":1749}"}, {"text": "Fortunately, the optimization is not as described in the same amount of detail as a figure two. And so in fact, you will in for two c, actually past two c. You do actually have to have this optimization, a form of this optimization implemented, but you're reasonable, free actually, how to implement it, because the paper actually doesn't describe very precisely how you should do it. And you have to do a little bit of work. But the basic idea is as follows.", "metadataJson": "{\"start\":1750,\"end\":1774}"}, {"text": "And just, instead of just voting or just saying no or yes as we on the previous slide, the rejection. So if you say no, the rejection includes a little bit of more information. And that information is going to help the leader to basically back off quicker. And so it includes something, what they call the conflicting term and the response and the conflicting index.", "metadataJson": "{\"start\":1774,\"end\":1801}"}, {"text": "And the conflicting term is basically the, uh, you know, if, let me actually make this a little more clear. Let's say we have s one, the timeline. Here's s two. So s two sends a, you know, it's elected leader in seven. Correct.", "metadataJson": "{\"start\":1803,\"end\":1821}"}, {"text": "Because it has the most up to date log. It sends a message, you know, to s one in a heartbeat. And in the heartbeat it will say, you know, the previous term was six and the previous index was five. And now when s one gets this, it looks at this log and sees that actually the previous term was five. So instead of, and so it will include in response the conflicting term where it conflicts on in that index.", "metadataJson": "{\"start\":1821,\"end\":1856}"}, {"text": "And that was five for the final entry. And then it also includes what the first index of that term is in this logic. So we look at this term like at 555 and the first time, like the index five showed up in log is at an index two. And so it will include that too. And we'll send that back to the leader.", "metadataJson": "{\"start\":1856,\"end\":1876}"}, {"text": "So here s was our leader, and so we're gonna send back, you know, five two as the conflicting information. And the leader uses that information to basically skip backward further. In fact, you know, it skips back, you know, from. So initially its guess was next index for s one was six. And based on this information it actually scales it back to two.", "metadataJson": "{\"start\":1876,\"end\":1906}"}, {"text": "So it turns it into two. And then the next append entries is going to include everything from two. So it's going to include 555 and previous term is four and previous index is one. And now as one can one swallow false swoop, basically copy the new lock entries over the entries 2345. And that sends back up to date.", "metadataJson": "{\"start\":1906,\"end\":1933}"}, {"text": "So this basically reduces the number of sort of heartbeats to catch up a follower by one per term instead of one per entry.", "metadataJson": "{\"start\":1934,\"end\":1943}"}, {"text": "Any questions? How do we make sure that we don't overload the bandwidth? Because imagine if you have trying to send back all of these log entries, could that cause problems in terms of packets that are too large? Yeah, sort of. Great question, because it indicates an alternative scheme back here is that instead of actually making this optimistic guess, you know, why make a guess at all?", "metadataJson": "{\"start\":1950,\"end\":1979}"}, {"text": "Just send everything the leader could have sent like its whole log and it would be perfectly fine. And then basically any of the followers can fish out the ones they need. Right.", "metadataJson": "{\"start\":1979,\"end\":1989}"}, {"text": "And that would be an alternative implementation. And presumably we don't like that implementation because the log might be large and that would be problematic. So I think the basic guess here that's going on is that in typical situations the followers are hopefully reasonable, close together. And so backing off a couple of entries is actually sufficient. And if not, then we might as well back up one term but not all terms.", "metadataJson": "{\"start\":1991,\"end\":2022}"}, {"text": "And so we'll send the lock entries for one term and that might be a lock. Right. That might be a lot and we'll see in a second, like how we get around that, right? Like snapshotting is going to help reducing the number of log entries that we have to send.", "metadataJson": "{\"start\":2023,\"end\":2036}"}, {"text": "So there was question on do you need to implement this sort of a version of this optimization scheme in lab two C? And the answer is yes, at least I believe. I haven't been able to pass the test without like implementing some optimization. So I have a question. So I, in my code, I did the optimization by backing off to the commit.", "metadataJson": "{\"start\":2039,\"end\":2061}"}, {"text": "So I made the reply include the last commit index and then I started from there. Is that much worse? You might run into trouble. So the tests keep track of how many bytes you sent and gives you a budget. And if you're like, go across the budget, you know, by too much, then the tester will say like, well, you're just sending too much data.", "metadataJson": "{\"start\":2061,\"end\":2088}"}, {"text": "Nice. Because in your scheme, it might be the case that I think you will send more data than really necessary, whatever necessary means. But there is a question in chat. Yeah, did I say draw the wrong thing? Yeah, 6666, sorry, thank you.", "metadataJson": "{\"start\":2089,\"end\":2109}"}, {"text": "Six, six, six. I don't want the follower overriding the leader's log entries. Sorry about that. Good catch.", "metadataJson": "{\"start\":2110,\"end\":2121}"}, {"text": "Any questions?", "metadataJson": "{\"start\":2124,\"end\":2125}"}, {"text": "Okay.", "metadataJson": "{\"start\":2132,\"end\":2133}"}, {"text": "Okay, so let me talk a little bit about the persistence. We have one question in the chat first. Okay. They're wondering why the rejection has to send back the rejected term number as well as the index.", "metadataJson": "{\"start\":2140,\"end\":2155}"}, {"text": "Well, that depends very much how you actually implement the, how, what kind of state you maintain on the leader and how the leader decides to back off. Do you need to know, send some terms back because you need a Tor. I mean, if a response gets delayed for a long period of time, you certainly should reject, you know, information from terms that are completely not relevant anymore. So I know this is slightly vague answer, but it really very much depended on exactly how you implement it.", "metadataJson": "{\"start\":2159,\"end\":2190}"}, {"text": "Okay, persistence, we talked about persistence a little bit in last graph lecture where we noted that a follower can only vote for one candidate, you know, per term, and therefore it needs to remember it's who it voted for and what actually the current term is. But there's sort of a larger issue around persistence, and that came up in one of the questions one of you just asked, which is, you know, what happens on reboot, and there's sort of two possible strategy you could think of, right? Like one strategy is strategy. One is, you know, basically the node joins sort of freshly, so joins basically when a node crashes and comes back up, it just doesn't participate anymore. It has to rejoin, you know, the rejoin the raft cluster.", "metadataJson": "{\"start\":2197,\"end\":2271}"}, {"text": "And that means, you know, when it rejoins, you sort of have to replay the log where it basically has to receive every entry in the log and then replay that. And of course, you know, like if a node has been down for, you know, node crashes and is down for a day or two days, or even if it just goes down for a second, but, you know, the system has been up for a year, then that would mean like you have to replay a lot of log entries. And so that's a little bit annoying. And so people prefer that strategy two, which is, you know, you can back up and you just basically participate again. So you catch up from, you know, you basically, you start from your persistent state.", "metadataJson": "{\"start\":2273,\"end\":2320}"}, {"text": "The idea being that like just a quick reboot, when you crash, you come back up quick network failure. And so maybe the rest moved one term along. You basically have all the state and it should be reasonably quick to catch up. So then the real question is like, what needs to be, what state needs to be persisted across reboots? Now we already talked about voted for, that needs to be persisted because you are not allowed to vote for another candidate in the same term.", "metadataJson": "{\"start\":2330,\"end\":2365}"}, {"text": "But the raft contains a little bit more information. It also maintains the log on disk or in persistent state and the current term.", "metadataJson": "{\"start\":2367,\"end\":2377}"}, {"text": "And for each one we should ask ourselves the question, why maintain it on persistent state? Because it means that whenever we update that state, whenever we append an entry to the log, or whenever we increment the term, or whenever we change forward, we actually have to write to disk or to stable storage. And stable storage is expensive, and so it's very likely that, for example, the writing to stable storage could be become a bottleneck. So we're already talking about voting force. I'm not going to cover ground, but let's talk about the log.", "metadataJson": "{\"start\":2382,\"end\":2419}"}, {"text": "Why does the log have to be written through persistent storage if we reintegrate?", "metadataJson": "{\"start\":2419,\"end\":2426}"}, {"text": "Another way of questioning, let's say we don't write it to stable storage. What would break?", "metadataJson": "{\"start\":2438,\"end\":2442}"}, {"text": "Yeah, someone in the chat sushi answered this question, which is you could lose the majority on the committed write entries. Right? So here's the scenario. The raft replicated the operation on a majority of the nodes. So somebody, you know, majority of the nodes actually committed to actually delivering, having accepted that log entry.", "metadataJson": "{\"start\":2455,\"end\":2483}"}, {"text": "So the leader sees the commitments, it delivers the message with the operation on the applied channel to the servers. The service executes the operation and lets the client know the operation has succeeded. So now basically we expose the fact that this actually operation was actually replicated in the majority of nodes to the client. And so if the followers that actually received that entry did not put it on disk and so that when they reboot, they still have it, we could run into the case exactly as the answer in the chat, that we lose the majority on a committed entry and that entry will not be delivered on the remaining replicas to the surface. And so the client will see something strange where it sees that an operation that it did actually happened, when a little bit later, that operation hasn't happened.", "metadataJson": "{\"start\":2483,\"end\":2537}"}, {"text": "And so it actually is important that this actually is unstable storage. Now, we basically promised the leader to commit it, and we cannot back out of that promise.", "metadataJson": "{\"start\":2537,\"end\":2550}"}, {"text": "Okay, any questions about this?", "metadataJson": "{\"start\":2553,\"end\":2556}"}, {"text": "Why do we need to remember the current term or on disk? Does that need to be stored stably?", "metadataJson": "{\"start\":2563,\"end\":2569}"}, {"text": "Well, the term, you vote for a different person in every term. So if you don't keep track of what term it is, then you don't really. You don't actually know who you voted for, right? Yeah, exactly. You don't really know where you voted for.", "metadataJson": "{\"start\":2573,\"end\":2586}"}, {"text": "That's one problem. Also, current terms always have to go up. Right. You cannot go down in term because you're going to use that to detect RPCs from stale leaders and stale candidates. But this always has to go up.", "metadataJson": "{\"start\":2586,\"end\":2601}"}, {"text": "Okay, any questions about persistence?", "metadataJson": "{\"start\":2610,\"end\":2616}"}, {"text": "I guess, which is more about the way you laid out stuff, but you say there's two strategies, right? Yeah. Replaying the log and starting from persistent state. Yeah. Um, and so I.", "metadataJson": "{\"start\":2627,\"end\":2644}"}, {"text": "The way you describe starting from a persistent state, um. Do you, like, do you, um, replay, like, I guess it doesn't say in the slide, like, if you have. Does that assume you also have, like, the snapshot of. I have not talked about snapshots at all yet, which we'll talk about in a second. That's actually the next topic.", "metadataJson": "{\"start\":2645,\"end\":2674}"}, {"text": "Okay. But the point is, okay, there's two strategies. After a node crashes, there's two ways to treat that node. One is a complete new node that never existed in the system ever. And so when it comes up, you add it to the cluster as if it's a new node.", "metadataJson": "{\"start\":2674,\"end\":2690}"}, {"text": "So basically the cluster goes from, you know, let's say you started with seven nodes. One guy crashes. The cluster has six nodes, it just happily proceeds whatever the other nodes do, the replication and all that kind of stuff, and then the seven node actually comes back up. There's two ways of. One way is to say, well, I just forget everything I did ever, I'll join the cluster again, and the other six nodes will bring me up to date, that will send the log to me and I'll redo the operations.", "metadataJson": "{\"start\":2690,\"end\":2720}"}, {"text": "And that can be costly, even with snapshots. So the second strategy is to say, well, if the same node seven comes back up again, it tries to reintegrate with its persistent state that it has basically in the hope that, for example, you went down for a couple nanoseconds, a microsecond or a millisecond. There's basically not much catching up to do at all because it already has all the state. Um, but it would like, uh, the, aside from the log, there's also like a state machine, right, that you've been like applying changes to. Yeah.", "metadataJson": "{\"start\":2721,\"end\":2759}"}, {"text": "So, yeah, let's talk about that. So there's, I think there's the next topic. Okay. I think you're so, you know, what about surface recovery?", "metadataJson": "{\"start\":2759,\"end\":2769}"}, {"text": "Sorry, I actually have another question on persistence. Yeah. When does the server decide to persist? Good, great question. What do you think?", "metadataJson": "{\"start\":2776,\"end\":2787}"}, {"text": "I'm sure you thought about this.", "metadataJson": "{\"start\":2788,\"end\":2790}"}, {"text": "I mean, I think a simple answer would be every time one of these variables changes. But that seems like a very costly thing to do. I think that this is the correct answer. Whenever one of these variable changes, you actually flush it to disk or you write it, in our case, correct. In the labs, you write to the persister module.", "metadataJson": "{\"start\":2793,\"end\":2816}"}, {"text": "Okay? So for example, when the leader accepts an entry through start and appends it to its logic, it actually has to persist that entry.", "metadataJson": "{\"start\":2817,\"end\":2828}"}, {"text": "All right? And so does the persisting work incrementally? So it like, once you get a new log entry, you append, or does that like take the entire state and like rewrite it into the file. Okay. In real life, you know, repent.", "metadataJson": "{\"start\":2833,\"end\":2847}"}, {"text": "Correct. And you would not rewrite the whole log, you would just repent that one entry to the log. And that's actually one of the reasons that logs are cool, because you can just append at the end incrementally. In our lab, the whole thing is fake. The persistor actually doesn't really persist.", "metadataJson": "{\"start\":2847,\"end\":2864}"}, {"text": "It keeps the object around between crashes. Because crashes are also fake. The tester basically stops nodes, restarts them, and basically gives them the new state. But in a real system, you would depend. So the log would be your file and you would append an entry to the file.", "metadataJson": "{\"start\":2867,\"end\":2886}"}, {"text": "Thank you.", "metadataJson": "{\"start\":2887,\"end\":2888}"}, {"text": "Yes, we actually, you all have to. In a real system, if you append a log entry, you first append the log entry, then you respond. So in the append entries, if you update the logo, if append entries on the follower that receives a new set of walk entries, it appends them to its local persistent log and then it can respond. Because it would be bad to respond before appending because then you might lose if you responded before appending, you might run in a situation where just before actually the actual pending happens, the crashes. And so you actually did not persist the log entries.", "metadataJson": "{\"start\":2894,\"end\":2931}"}, {"text": "And so you would, you know, you could lose committed entries.", "metadataJson": "{\"start\":2931,\"end\":2935}"}, {"text": "Okay. Okay, so how about service recovery? So the service keeps its own state. Like for example in web three, you're implementing a key value store. And so the key value store maintains basically a hash map from key to value, and you need to replay that state.", "metadataJson": "{\"start\":2940,\"end\":2960}"}, {"text": "And again, there are two possible ways of going about it. One strategy one is to replay the log to actually reconstruct that state.", "metadataJson": "{\"start\":2961,\"end\":2971}"}, {"text": "So basically, if you're this sort of similar to the strategy one on the previous slide, you just take the log, you just replay all the entries in the log. And that should basically create exactly the same state as if, as before. Because the whole point of this replicated state machine approach is that all the operations are executed in total order, the operations have no side effect. So if you start in the same state like nothing, and replay all the operations, you should end up exactly in the same state as any other node. So that's one possible.", "metadataJson": "{\"start\":2974,\"end\":3013}"}, {"text": "And so that was one way to recreate the state.", "metadataJson": "{\"start\":3014,\"end\":3017}"}, {"text": "And obviously this is expensive. The service actually has been running for a couple years, and you have to replay the logs from the beginning of time. That is not so desirable. And so clearly people don't really follow strategy one, but they follow another strategy, and which is like basically making periodic snapshots. And there are two reasons to doing that.", "metadataJson": "{\"start\":3024,\"end\":3049}"}, {"text": "One, to basically reconstruct the server state in a fast manner. And the second reason to do that is to be able to compact the log. Even the raft state itself can be cut off, or the front of it. The prefix can be cut off. And the basic observation is that if the application is running for a while and it just has applied, say, the first thousand operations or the first million operations, then the state that is constructed that point, the state will contain all ops, you know, say through I, where I maybe a thousand or a million, whatever, you know, whatever you.", "metadataJson": "{\"start\":3049,\"end\":3094}"}, {"text": "So one way to think about is that there's sort of a duality between state replication and log replication or replay. You can save the state after 1000 operations and then you got exactly the same thing as actually reapplying or redoing every operation from zero to 1000. And so this means that like once you have a snapshot and you store the snapshot, stabilize on disk in persistent state, you can cut off, you can cut the log through I.", "metadataJson": "{\"start\":3094,\"end\":3133}"}, {"text": "And so this allows you to control the size of the log basically by periodically asking the servers to actually take snapshots. And then, you know, the servers telling the raft library, yes, I've taken a snapshot through I, then raft can say, okay, good, I just don't have to remember anything from I or until I. That means of course that the snapshot has to be stored on stable storage and this is also good for recovery. Correct. And so it makes our recovery scheme slightly more complicated than I just described in the previous slide.", "metadataJson": "{\"start\":3136,\"end\":3170}"}, {"text": "You know, what has to happen is that when a follower comes back up after a quick, say, reboot, it loads its persistent state. That includes the persistent state that we talked about on the previous slide. That's disinformation, but also its last snapshot installs that last basically loads that snapshot into memory. The surface does, and then we can replay any log entries to basically bring the follower up to date. Okay, any questions about this?", "metadataJson": "{\"start\":3170,\"end\":3210}"}, {"text": "I had one question. I'm not sure if I'm going to be able to phrase it super clearly, but I guess like, I was under an impression. So I guess like, does this not break some layer of abstraction that previously existed between the application on top of raft and raft itself, where it now needs to understand how to state machine? Like how to apply commands to the state machine instead of just giving commands to some external state machine? Yeah, great observation.", "metadataJson": "{\"start\":3212,\"end\":3244}"}, {"text": "Clearly there is some, you have to play together the raft library and the surface because first of all, the service lies about like, you know, gives the wrong information about like how far it has applied. Then, you know, we get inconsistent results. But anyway, so we, we don't assume wires anyway. But it's clearly the case that the service and raft library have to cooperate and you can call that an abstraction violation. I think the reason to do it is to limit the amount of state that the raft library has to maintain.", "metadataJson": "{\"start\":3246,\"end\":3281}"}, {"text": "Otherwise the raft library wouldn't know when it can cut the log. And so there's basically no way around it that the server actually tells it. Like, well, I got a snapshot through I, and so it's okay for you to remove log entry from zero through I and you'll see that. And so this is maybe a good point. This is going to come up in 2d lab.", "metadataJson": "{\"start\":3281,\"end\":3304}"}, {"text": "2D is going to is all about snapshots and lock compaction, as it's also called in the paper.", "metadataJson": "{\"start\":3304,\"end\":3311}"}, {"text": "There has to be some API between the servers and raft to be able to collaborate. And basically in two a and two b that API. In fact, even in two C, that API is extremely simple. The only API that exists is basically delivering log message on the apply channel. Almost nothing flows down from the service to the raft library other than that the service may start and raft tries to append an entry to the log using raft start.", "metadataJson": "{\"start\":3314,\"end\":3342}"}, {"text": "In 2D, there has to be a little bit more of an API between the service and raft library. It turns out you can design that API in many possible ways. There are quite a number of ways of doing it. There's not particularly one, and the paper doesn't lay out what API you should use. The paper actually says nothing about this.", "metadataJson": "{\"start\":3344,\"end\":3366}"}, {"text": "It's up to you, it's up to us to figure out what the API is. And to be able to do 2D, we have to declare an API between the servers and raft. You'll see once you do 2D, that API has some funny, might be a little bit more different than you might expect it. And we had to pick one particular API.", "metadataJson": "{\"start\":3366,\"end\":3393}"}, {"text": "In that API there's an operation called conditional install that has semantics that allows you to change the raft state and the server state atomically in one single operation. And partly that operation exists to try to limit the abstraction by arrays.", "metadataJson": "{\"start\":3395,\"end\":3421}"}, {"text": "And it turns out you can do it in different ways. You don't really need. You could have written it in different ways, but I personally think it's actually one of the more simple ways of doing it. But that will become more clear in two D and you'll see indeed that there's sort of a interaction between the servers and raft in a way that they have to play along.", "metadataJson": "{\"start\":3424,\"end\":3442}"}, {"text": "Could you repeat when raft communicates with the servers in the snapshot process? So the snapshots are driven by the surface. So the service just says, once in a while to raft, I've made a snapshot. Here's my snapshot. And this is a snapshot includes all the operations through I.", "metadataJson": "{\"start\":3448,\"end\":3466}"}, {"text": "And then Raft writes the snapshot and truncates log to I and writes all that information to the disk. And that's basically all what happens sort of in sort of regular operation, periodically snapshots happen, snapshot happens. Then there's the other case you will have to consider is like when a reboot happens. And so when the follower reboots, it actually reboots from its persistent state and so including its snapshot. And so when the follower reboots, you know, basically loads, you know, the snapshot from memory, from persistent disk, and actually reconstructs the application state the key value store and you will do this in lab three.", "metadataJson": "{\"start\":3466,\"end\":3509}"}, {"text": "So this is not going to be an issue in lab two. The only thing that is going to be an issue in lab two is that because the followers, because the log has been cut, right? Like, you know, instead of like having all the entries from zero to I in the log plus more so I, you know, n, the log has been cut from I to n, right. And that's another part of the law compaction. That also means that if a follower is far behind, like for example, a new node joins the system and doesn't actually have the beginning of the log nor the snapshot, then the raft has to communicate the snapshot to that follower.", "metadataJson": "{\"start\":3509,\"end\":3558}"}, {"text": "So in the case that the follower is before I, because it rejoined the lab and it rejoined the raft cluster, the leader actually has to send the snapshot to the follower and the follower basically starts from there. And that will show up in two D. And so there's an additional RPC called the snapshot RPC or install snapshot RPC that's described in the paper that you will have to implement in 2d. In fact, this brings me to a good point, actually. Let me first go to consumer, basically brings me to the homework question, which is here's the install snapshot RPC equivalent of figure two, but then just for the snapshot accuracy, and you actually have to implement that in two D.", "metadataJson": "{\"start\":3559,\"end\":3617}"}, {"text": "And one issue that came up, which was the homework question for today, is, is it every possible in raft? What avoids it? If it's not possible that the state machine rolls back? So for example, a leader sends maybe, you know, maybe an old snapshot shows up, you know, at a follower. Is it possible that, you know, if it's possible, if that the follower would install that snapshot and then implicitly basically roll back to state machine.", "metadataJson": "{\"start\":3617,\"end\":3649}"}, {"text": "Right. Maybe it already has seen more information. Clearly that seems not right. And so really the question is, how does wrap get around it? So maybe this is a great place to actually do a quick breakout and you can debate that homework question for a couple minutes, five minutes, and then we'll come back and we'll talk about a little bit more about snapshots.", "metadataJson": "{\"start\":3649,\"end\":3674}"}, {"text": "Lily, wouldn't be on one eight? No. Lily, how about I try? You can make, I'll go for it. Yeah, hold on.", "metadataJson": "{\"start\":3676,\"end\":3685}"}, {"text": "I'll probably have to make you host and then you can do it. Okay. You should be host now. Awesome.", "metadataJson": "{\"start\":3685,\"end\":3697}"}, {"text": "It.", "metadataJson": "{\"start\":3700,\"end\":3700}"}, {"text": "All right. Should be. Thank you, David.", "metadataJson": "{\"start\":3726,\"end\":3730}"}, {"text": "And I'll go ahead and make you host again. Yeah, that'd be great. Thank you.", "metadataJson": "{\"start\":4086,\"end\":4091}"}, {"text": "Perfect.", "metadataJson": "{\"start\":4093,\"end\":4094}"}, {"text": "Let me see. I got to reshare my screen.", "metadataJson": "{\"start\":4115,\"end\":4117}"}, {"text": "Yeah, everybody back online.", "metadataJson": "{\"start\":4134,\"end\":4136}"}, {"text": "We're good to go. If somebody can respond, that'd be great.", "metadataJson": "{\"start\":4139,\"end\":4143}"}, {"text": "Okay, good, good. Okay, great. I hear that sometimes people, because of the breakout rooms, past rooms, breakouts, but hopefully, I don't know exactly what to do about that because we're a class and fault tolerance is a little bit unfortunate that people get just dropped. Okay, so any, I think the homework question this time around was reasonable, sort of straightforward. Clearly it has to be the case that you cannot install an old snapshot because servers that might have had a more recent snapshot might have responded to the client saying like, yeah, your operation succeeded.", "metadataJson": "{\"start\":4146,\"end\":4192}"}, {"text": "And then if you would restore an old snapshot, then you basically back out to the state and the client would see there's certainly an old version of the serf, so that's certainly not legit. And so there's a little bit, you should definitely reject old snapshots, but you have to be a little bit careful. If you know the follower has a log that goes beyond the snapshot, you have to keep that remainder part of the log because basically you have promised to a leader that you have accepted a message and so you can delete the rest of the log that is not covered by the snapshot. Okay.", "metadataJson": "{\"start\":4192,\"end\":4231}"}, {"text": "Okay. So then let me return.", "metadataJson": "{\"start\":4235,\"end\":4237}"}, {"text": "We had a question, actually. Okay, go ahead. So it says, it says in the paper, right, if the call receives a snapshot, that's a prefix of its log, right? Yep. The log entries covered by the snapshot are deleted, but the rest are kept.", "metadataJson": "{\"start\":4241,\"end\":4259}"}, {"text": "Yep. In that case is the state machine. The state machine wouldn't be overwritten. Right. In this case.", "metadataJson": "{\"start\":4259,\"end\":4269}"}, {"text": "Okay, so the interesting question is like how does the snapshot get communicated to the state machine? And as you will see in lab three, that it goes over the apply channel. And so the state machine will get the snapshot over the apply channel and then it's up to it to do the right thing. Okay. Okay.", "metadataJson": "{\"start\":4269,\"end\":4293}"}, {"text": "Okay, good. Just a follow up on that. Sorry. Yeah. Though I was a little bit, so that makes sense to me.", "metadataJson": "{\"start\":4296,\"end\":4303}"}, {"text": "The part that I was confused by is in the, in the figure 13. Like the box that describes install snapshot RPC. Yep. On six it says if existing log entry has the same index as the term snapshot lasting include entry.", "metadataJson": "{\"start\":4303,\"end\":4319}"}, {"text": "Hold on, I might have just misread it. Okay, why don't you keep thinking about it? Then we'll. Yeah, if I have a question. I'll ask.", "metadataJson": "{\"start\":4324,\"end\":4332}"}, {"text": "Yeah, I'll take it offline and we'll do it right after lecture, if you want to. Okay. I want to go back, actually, for a couple minutes. You know, that we have remaining and talk about actually using Raft, which is sort of a discussion that we're already basically having here for a service. And so again, I'm going to focus on the replicated key value servers.", "metadataJson": "{\"start\":4333,\"end\":4351}"}, {"text": "That is going to be the topic of lab three. And so, just to go back to almost like one of the first boards that I drew at the beginning of the RAF lectures, here's like our boxes that correspond to the three replicas.", "metadataJson": "{\"start\":4351,\"end\":4366}"}, {"text": "And each replica, correct, has a sort of split two pieces. One is the surface part and one is the Raft library. We know that basically days communicate these two through the applied channel, and that's the way the information flows from Raft to the service.", "metadataJson": "{\"start\":4369,\"end\":4393}"}, {"text": "And so clients interact with the service, not directly with raft. So we have a client here that sends operation, like a put operation or a get operation to the service. The service receives this operation, and it basically calls start for that operation. Then Raft does its chitchat with the other raft libraries. Messages can flow back, and at some point the operation is committed, and then it actually is.", "metadataJson": "{\"start\":4395,\"end\":4427}"}, {"text": "Raft will say, this operation is ready to be committed, sends it on the apply channel, and the servers then basically execute the operation and send the response back after it executed the operation, and responds back to the client saying, like, well, the value for the get key 20 is this. This is a get operation or put. And this is basically the value for the get or. Okay, if the put succeeded. And we also discovered in the last lecture that it might be the case that the client sends an RPC to the service and the RPC disappears.", "metadataJson": "{\"start\":4427,\"end\":4465}"}, {"text": "So the client was recent, and by the time it resends, actually, the leader might not be the leader anymore. And so in that case, it has to redirect itself to another leader. And so basically what, there is a little bit of code to think about this. There's a little bit of code at the client side, sort of understands replicated state machines a little bit. And it maintains some information.", "metadataJson": "{\"start\":4466,\"end\":4487}"}, {"text": "It maintains like who's the leader and who are the other followers? And so that can switch between them if necessary. We also, last time we talked a little bit about that. It's possible that operation can be duplicated because client may send an operation put operation to the servers and. But, you know, the client doesn't get a response, but the servers actually received it.", "metadataJson": "{\"start\":4488,\"end\":4516}"}, {"text": "So it went through, you know, went through the whole operation sequence, you know, starting the raft append, going through the raft motion, and then basically sending it out to the client channel. And so basically the client actually might, you know, send a second one, and, you know, the. And basically for the repetition, that might actually go through the raft library, too, comes out in the apply channel. And so you have to do some duplicate detection. There are multiple ways of doing it, but either way you have to do duplicate detection.", "metadataJson": "{\"start\":4516,\"end\":4548}"}, {"text": "In addition to maintaining some state about what the leader and the followers are, the put and get also actually have an idea, an idea associated with it. And the client needs to maintain what is the last id that it actually is trying to get through, and that is used to actually do duplicate detection. And this little piece of code is often called a clerk, the clerk that interacts with the service and that does a little bit of work to collaborate with the servers to actually get the right thing done. And so we have multiple clients, all have a cleric library, if you will, which is a go package. And the clients basically talk.", "metadataJson": "{\"start\":4548,\"end\":4589}"}, {"text": "Putin gets over that interface, and inside of the cleric actually maintains these ids, or maintains one id for the outstanding put and get operation, as well as some information about who's part of the cluster. Does that all make sense? So that's the basic structure. Correct. And how raft fits into a larger picture.", "metadataJson": "{\"start\":4589,\"end\":4610}"}, {"text": "The one question that comes all the way up is, what is the guarantees that the servers and the clerk together make to declines about these put and get operations? So this really means, what is the correctness criteria?", "metadataJson": "{\"start\":4611,\"end\":4628}"}, {"text": "And the way we always have described it so far, we've been reasonably sloppy about it, or I've been sloppy about it. And basically I've said it's like, well, it should behave like a single machine, but even that is sort of a little bit of an imprecise definition, because what happens if two clients basically, at the same time, execute a pudding or get operation? And what actually is the correct outcome of these operations? So we really need a sort of a little bit more preciser. I think behaving like a single machine is the right intuition, but we need a little bit of preciser definition.", "metadataJson": "{\"start\":4631,\"end\":4672}"}, {"text": "And this definition, you saw the term used in the paper, and this definition is called linearizability.", "metadataJson": "{\"start\":4672,\"end\":4679}"}, {"text": "And linearizability is basically a spec, you know, specification of what values a put and a get operation can return. Particularly since put doesn't really return, an operation is really what get can actually return. And it basically says, like, what are allowed things to be returned, and what are things that are not allowed to be returned independent of actually how you implement it. It's just like purely a specification, and it basically has three components to it. Linearizability.", "metadataJson": "{\"start\":4684,\"end\":4710}"}, {"text": "Linearizability says, like if you have to look at some sequence of operations and some of them executed concurrently, it has to be the case that there's a total order, so you can arrange all the operations in some total order operations. Two, it has to match real time with that. I mean that if an operation completed before a second operation started, even if those operations are different machines, it has to be the case that in this total order, the first operation shows up before the second operation.", "metadataJson": "{\"start\":4712,\"end\":4761}"}, {"text": "And that sort of makes sense, right? Like if it behaves like a single machine, and you start an operation after another operation, then the single machine would always return the results of the first operation. So and then finally a read operation. So this is like in our case, in the key value server, it only has one read operation, namely get. But the read operation should always return the results of the last write.", "metadataJson": "{\"start\":4764,\"end\":4790}"}, {"text": "So in our case, we do a get operation, and the put operation happened well before it and completed well before then, that get operation should observe the last, should observe the last put. Okay, so this sort of, these are the three conditions that would determine whether a system actually has linearizability. And you can think about linearizability as well. Well, this behaves like a single machine. So let me make it a little bit more concrete, because this is a little bit abstract.", "metadataJson": "{\"start\":4796,\"end\":4829}"}, {"text": "And the way basically people think about linearizability or argue that a system has linearizability, but is we're looking at particular histories or executions, and then see if you can use histories, if you can turn that into a total order, even though the operations actually might have actually executed concurrently. So let me give you one example, a very trivial example. So let's say we have three clients, c one, c two, c three, and they do a bunch of puts and gets in typically the way, you know, you basically say there has to be some start point where the operation started, and there's some endpoint where the operation ends. So for example, when actually the client actually gets the return from the surface. And so let's say this is right operation, you know, to the value, to the variable x, and we write one to it.", "metadataJson": "{\"start\":4830,\"end\":4885}"}, {"text": "So the client one started at some point in operating a write operation to the variable x to write one, and it ends at some point here, maybe did a second one and writes two to it, and then maybe we have all the action with linearizability is when operation happens concurrently. So some operation starts before another one actually finishes. So, for example, we might have the following operation. Client two does a read operation in our case would be a get. And there's a read, you know, of x, and the value returned by this operation is two.", "metadataJson": "{\"start\":4885,\"end\":4920}"}, {"text": "And then we have a similar sort of situation where on client three it actually starts an operation, a read operation, and it reads x and it returns one. Let me make this a little bit more clean. The read operation actually returns before, you know, the write to operation starts or ends, and same from rh one. And then the question that always comes up, is this a linearizable history? Is this a linearizable execution?", "metadataJson": "{\"start\":4920,\"end\":4949}"}, {"text": "And if it's linearizable, then basically it means like this could happen on a single machine too. So could this happen on a single machine? We can just like abstractly think about it without actually having.", "metadataJson": "{\"start\":4951,\"end\":4963}"}, {"text": "Is this a legit outcome for, basically what we need to look at is the outcomes of R two and C two and RSC three. You know, is this a legit execution? I'm not sure. I don't really know what it means for our rights to take like a long time. Well, take a long time, for that matter.", "metadataJson": "{\"start\":4965,\"end\":4985}"}, {"text": "Yeah. If you think about from the client perspective, it sends a request to the service. So that's the starting of the write, and it got a return value at some point from the servers, and that's the end of the write. And so in between, all kinds of stuff happens, right? It went actually into the servers.", "metadataJson": "{\"start\":4985,\"end\":5004}"}, {"text": "The servers, you know, put it into draft, draft, ran, went to the apply channel, blah, blah, blah. Lots of stuff happened. We don't really care exactly what the implementation does. At some point it got the response. And so you can think about this.", "metadataJson": "{\"start\":5004,\"end\":5015}"}, {"text": "You know, there's basically three concurrent clients. You know, they issued concurrent operations. And we were wondering if this is actually legit outcome.", "metadataJson": "{\"start\":5015,\"end\":5022}"}, {"text": "I don't think this could happen on a single machine because the write for two, it finishes after the read starts. Oh, sorry. Yeah, yeah, that's right. But it seems like the write should happen before the read. And in this situation, it, it couldn't happen if the write started after, if they, if the ride finished it after the rides restarted.", "metadataJson": "{\"start\":5025,\"end\":5056}"}, {"text": "Yeah, yeah. Okay, so one way to think, one way to think about it is that we can move, you know, we have to construct a total order, right? And we can construct a total order where all the, you know, the operations line up. Then, you know, it's a valid linearizable history. And so let's construct the total order and then go back to this question that you just asked.", "metadataJson": "{\"start\":5056,\"end\":5076}"}, {"text": "So a total order, here's a total order that I, I'm going to, so I'm going to do first the write operation, then the read x one, then the write x two and then rx, and then the read of x two. Right. This is total order. All the operations are now happening sequentially. And we need to check whether this total order is correct corresponding to the linearizability definitions.", "metadataJson": "{\"start\":5076,\"end\":5103}"}, {"text": "Well, it has to be the case that operations that start, if an operation starts after some other operation ends, it needs to be after in the total order. And so we look at this, let's look at this. This one must start after wx one. And that is true. Correct.", "metadataJson": "{\"start\":5103,\"end\":5120}"}, {"text": "In this total order, rx one must start after wx one because it actually returns the value. And in our total order, that is also the case, rx two must start at wx two because it observes the result of this write. And that's perfectly fine too. We can basically, one way to think about it is that even though they execute in this way, we can rearrange things to fit the total order. If we think about this, then this is a total legit execution where, you know, the operation format of the order.", "metadataJson": "{\"start\":5120,\"end\":5162}"}, {"text": "And so this is like what a single machine would do. So a single machine could execute at the right double x one, read x one, write x two, read x two, and we all perfectly fine.", "metadataJson": "{\"start\":5162,\"end\":5172}"}, {"text": "Okay, so let me make me helpful to think about a history that is not linearizable. So let me look at a second one.", "metadataJson": "{\"start\":5174,\"end\":5182}"}, {"text": "And I'm going to come back on this on Thursday anyway, so don't worry if this not make sense yet. But here's another one. I got c one. Same thing. Write x one.", "metadataJson": "{\"start\":5189,\"end\":5203}"}, {"text": "I got a c, and here, right, x two. And there's going to be a read that actually goes in x one. And, I'm sorry, read x two. And then I got a c two, c three. And the c three starts after the other read and returns one.", "metadataJson": "{\"start\":5204,\"end\":5232}"}, {"text": "And the claim here is that it's not possible to construct a total order that matches a linearizability. And one way, one indication of this is that this read that returned x one started after the read that returned to. And I will make this a little bit more precise later. But in a real single machine system, that could have never happened because that would have meant that the value changed between rx two and rh one. And you know, with these few operations that we here have on the board, it has to be the case that this rh one happened after that write.", "metadataJson": "{\"start\":5234,\"end\":5276}"}, {"text": "And this write must have happened after that write because they're in total there. We have to respect, you know, the ordering of the single of c one. And so there's no way to basically slot in the total order. According to this picture, it should go after rx one.", "metadataJson": "{\"start\":5277,\"end\":5299}"}, {"text": "But that can really not be true because if it got after rh one, that Nand is also after wx two. So that must have read two and not one. So this is not a linearizable history in execution.", "metadataJson": "{\"start\":5301,\"end\":5319}"}, {"text": "Another way of saying that is that basically what is RXM returning here is really returning a stale value. And that is not allowed if a machine behaves like a single machine or replicated server behaves like a single machine. And so I'm going to come back, you know this to the lecture when next week when we talk about zookeeper, because this is going to be a very important, like this notion of linearizability, sort of a thing that shows up prominently in the paper. And this notion of state of values also shows up prominently. And since I'm running out of time and there's, I'll resume that next week.", "metadataJson": "{\"start\":5325,\"end\":5363}"}, {"text": "Okay, any further questions and people that need to leave, please feel free to leave. And in fact, I hope you did, you don't want to make, be responsible that you miss other classes. Is this considered like, what type of consistency is this considered to be, like, strong consistency.", "metadataJson": "{\"start\":5364,\"end\":5387}"}, {"text": "This is considered to be invasively strong consistency. And what it really is is sort of a precise definition of what strong consistency is. So like our intuition about what strong consistency is, namely behaving like a single machine, that the precise definition that people use in the technical literature is linearizability.", "metadataJson": "{\"start\":5389,\"end\":5407}"}, {"text": "How did they decide to have that property? Like why did they decide to have that property? There's a couple of things. One reason, the reason, okay, so it makes sort of sense. So if you think from this point of view, like you want to behave, you want to make a replicated system behave like a single machine or unreplicated machine, and you want to only allow outcomes that actually correspond to executions that the single machine could have done the next.", "metadataJson": "{\"start\":5412,\"end\":5440}"}, {"text": "Linearizability is a very intuitive definition for that. The database world has also some other terminology, like serializability. This is also a term that will show up in the term later. And basically the only difference between linearizability and serializability is that serializability doesn't require, that matches real time. And so people have sort of different definitions of strong consistency, if you will, and the one that we'll see most prominently is linearizability, which corresponds closest to, like, the machine behaves, the replicated server behaves like a single machine.", "metadataJson": "{\"start\":5440,\"end\":5475}"}, {"text": "Thank you. You're welcome. I have a question about what happens during, like, a network partition. Yep. So I know, like, so if a leader gets partitioned completely on their own, they'll eventually time out, but if they have sort of, like, a few followers with them, they'll stay the leader, and they won't be able to commit anything because they'll be in a minority, and there'll be a new leader, and they'll be.", "metadataJson": "{\"start\":5480,\"end\":5508}"}, {"text": "So will that leader ever sort of recognize that maybe it's a sale leader? Or do we just assume that eventually, if the partition goes away, it'll figure out? Because, like, I'm worried, if there's a client that's talking to the sale leader, what does that client do?", "metadataJson": "{\"start\":5509,\"end\":5527}"}, {"text": "Okay, so this is a great question with this picture here. Hopefully it will help. So the client talks to this guy. Correct. Like, who's the leader?", "metadataJson": "{\"start\":5531,\"end\":5540}"}, {"text": "You see the picture? I just want to double check that you can see it? Yeah, I can see it. Okay, good. So let's say, you know, this first box is the leader.", "metadataJson": "{\"start\":5540,\"end\":5546}"}, {"text": "Client talks to that leader. The leader can't commit any operations. Correct. And so it won't communicate anything on the apply channel. And so it will never respond to the client because there's, like, no operation actually being, its operations are not being executed.", "metadataJson": "{\"start\":5546,\"end\":5561}"}, {"text": "So the client will just retry and just keep retrying forever until the client actually maybe tries another, you know, one of the other followers. Correct. It maintains, you know, who else is actually in the group, or until the network heals and the leader actually could commit an operation. Gotcha. Wait, so doesn't the leader immediately reply, though, saying, I got your request request, or does it wait until it's committed in lot three?", "metadataJson": "{\"start\":5561,\"end\":5595}"}, {"text": "It doesn't communicate with the client until it actually has processed the request, which means that the operation actually has run through raft and come out of the applied channel and has to be executed by the service. Okay, does that make sense? Yeah. So then the client could just implement a timeout where they're like, if it's a certain amount of time and they haven't received the commit, assume that maybe I should try a different node. And then if it gets the new leader or a follower of the new leader, it'll.", "metadataJson": "{\"start\":5595,\"end\":5626}"}, {"text": "It'll be back to normal operation. So this clerk, that's exactly what this clerk sort of does, you know, sort of plays along with the serves to actually do what you just said. Got it. Okay, thank you. You're welcome.", "metadataJson": "{\"start\":5626,\"end\":5641}"}, {"text": "Sorry, can you repeat again what the clerk does? The clerk is a little bit of like a stub or like a little library client links with. And so the client calls, puts and gets. And the clerk actually is the interface that it talks to. And the clerk can keep some information like who's part of the raft cluster.", "metadataJson": "{\"start\":5642,\"end\":5662}"}, {"text": "So who's the leader and who are the followers? At least what it thinks is the leader and the followers. And when it sends an RPC to the servers, it sends it to the leader, but it thinks it's the current leader. And the servers in the whatever thinks it's the current leader. The leader might actually respond saying like, hey, I'm not their leader, you should send it somewhere else.", "metadataJson": "{\"start\":5662,\"end\":5682}"}, {"text": "And then it will try one of the others and updates its information. And also we'll tag every put and get operation that it receives from the client. And it sends to the servers with a unique id so that the service can do duplicate detection. And this all comes up in lab three. So you will see there in lab two there's no real clerk because the tester basically sits on top of the directly of the raft interface and doesn't really interact through the clerk, but in lab three will interact through the clerk.", "metadataJson": "{\"start\":5682,\"end\":5715}"}, {"text": "So how did the clients generate unique ids as they, with each other? Random, big random numbers. Okay, so we're just guessing and hoping rather than actually guaranteeing some sort of like incremental. One way to make it more guaranteed is for example, take your ip address and append and random number.", "metadataJson": "{\"start\":5716,\"end\":5737}"}, {"text": "A question about the homework question. Yeah. So I thought that it could go backwards in time. Like I read the paper and it said on page twelve, let me pull it up. It said that the, if there's a conflict, right, then the follower just discards this entire log and it's also preceded by the snapshot.", "metadataJson": "{\"start\":5741,\"end\":5759}"}, {"text": "So I wonder why.", "metadataJson": "{\"start\":5760,\"end\":5762}"}, {"text": "Let me guess. I don't really know exactly the sentence what you're referring to and I have to look it up again. Oh, it's on page twelve. It's at the, it's towards the end of page twelve, the second column here. So the second to last paragraph.", "metadataJson": "{\"start\":5765,\"end\":5778}"}, {"text": "So the log can go back, right. But not the state machine. Not. Oh, the log can't. The log can go back but not the state machine.", "metadataJson": "{\"start\":5778,\"end\":5785}"}, {"text": "Oh, is the state machine like what you. The committed entries, right? Yes, the log can go back because of blocking, uncommitted entries can go back. This is like this whole erasure stuff that we talked about earlier. Okay, so actually the log can go back.", "metadataJson": "{\"start\":5785,\"end\":5803}"}, {"text": "Yeah. Not the state machine, which is basically what you committed already. Yeah. And the log can never go, will never go back. We never bail out a committed operation.", "metadataJson": "{\"start\":5803,\"end\":5813}"}, {"text": "Correct. It can only bail out of. Erase uncommitted operations. Yes, that is right. Okay, got it.", "metadataJson": "{\"start\":5813,\"end\":5819}"}, {"text": "That's what I said. Can I ask a question about the third slide? Yeah, I guess the one right before this one. So could you just walk me through real quick what match index is doing on the right, like when s two is communicating with s three. Okay.", "metadataJson": "{\"start\":5819,\"end\":5838}"}, {"text": "So it starts out as zero. Yep. So s two is communicating with whom? S three. Yeah.", "metadataJson": "{\"start\":5838,\"end\":5846}"}, {"text": "So basically. Okay, so here match index is zero. Right. Like so. And let me write it down as zero.", "metadataJson": "{\"start\":5846,\"end\":5852}"}, {"text": "Yeah. Okay. And then it gets an o bag. So match index stays zero. Correct.", "metadataJson": "{\"start\":5853,\"end\":5858}"}, {"text": "Okay. Nothing there. But now it gets an okay back. So what does that imply? That implies that, you know, what?", "metadataJson": "{\"start\":5858,\"end\":5867}"}, {"text": "What did it send? It sent in heartbeat. Correct. With four index 13 and include. And the s three responded.", "metadataJson": "{\"start\":5867,\"end\":5881}"}, {"text": "Okay. And so it means that basically s three is up to date through until 13. Correct. That as next index that it actually has that expects 13. And so the s two knows now that its log matches until 13.", "metadataJson": "{\"start\":5881,\"end\":5896}"}, {"text": "After this message. Is it until 13 or until twelve? It matches till 13. So the next thing that will be sent will be go in index 13. So, so the next index and match index are going to be 13.", "metadataJson": "{\"start\":5897,\"end\":5913}"}, {"text": "Yeah. The next index is not used yet. Correct. Means empty.", "metadataJson": "{\"start\":5913,\"end\":5916}"}, {"text": "So basically they wait, you know, they, they. You can do it either way. Correct. You can either say the last one or they're in the first. That's going to be or the first next, you know, one.", "metadataJson": "{\"start\":5918,\"end\":5929}"}, {"text": "And in this case they go by the first next one. So in this case, both of them are 13 for the next one. Yeah. So basically if you can think about this at this stage. Correct.", "metadataJson": "{\"start\":5929,\"end\":5941}"}, {"text": "Before, like all the green stuff has happened, the match index for three is 13 and the match index for itself for two is also 13.", "metadataJson": "{\"start\":5941,\"end\":5962}"}, {"text": "Got it. Awesome. Thank you. You're welcome.", "metadataJson": "{\"start\":5964,\"end\":5969}"}, {"text": "Actually, can I ask a follow up on that? So when it sees that something matches. So for example, here on position eleven, it saw that it matches. Then is it is a guarantee that everything before that matches too? Yes.", "metadataJson": "{\"start\":5971,\"end\":5992}"}, {"text": "Right. Because. Hold on, let me double double check. You're talking about this message. Yeah.", "metadataJson": "{\"start\":5992,\"end\":5997}"}, {"text": "About like when it says ok, it checks index eleven. Yeah. Because that is the whole reason that this previous term and previous index are communicated. Correct. To the follower to make double check that it can only respond to ok.", "metadataJson": "{\"start\":5997,\"end\":6011}"}, {"text": "If indeed, is the case that in the previous index, eleven actually term free. And if that's true, that means that basically everything before that must match. And this is like this, whatever the statement, they call this invariant that they maintain that, like if something matches it, like one index, then everything before that must match two. Oh, okay. Okay.", "metadataJson": "{\"start\":6012,\"end\":6037}"}, {"text": "This is the invariant. Okay, I see. Oh, and I had another follow up question. It was related to the question on the lecture question that I wrote. I asked about the copy on write for creating snapshots.", "metadataJson": "{\"start\":6037,\"end\":6053}"}, {"text": "No. And I think. I don't really understand what is being copied. Is it, is it the page tables or is it. I think, I think I responded, yeah, I read the email, but I still want.", "metadataJson": "{\"start\":6053,\"end\":6067}"}, {"text": "Okay, okay, good. Okay, good. Hold on a sec. Let me catch my breath. The.", "metadataJson": "{\"start\":6067,\"end\":6074}"}, {"text": "So, okay, the scenario is snapshots can be expensive because the snapshot might be large. It's a gigabyte key values page table. I'm sorry, not the page table. If it's a gigabyte key value store, then you need to write that gigabyte to disk. And while you're writing it to disk, if you don't do anything clever, you cannot process any other boot and get operations that come in through the channels.", "metadataJson": "{\"start\":6075,\"end\":6108}"}, {"text": "Let me actually pop up this picture. Correct. So basically the service decides at some point to make a checkpoint. It's a gigabyte. You have to write a gigabyte to disk.", "metadataJson": "{\"start\":6108,\"end\":6117}"}, {"text": "That's expensive.", "metadataJson": "{\"start\":6117,\"end\":6118}"}, {"text": "I think the plan that the paper is hinting at is that what the service does, it calls fork.", "metadataJson": "{\"start\":6120,\"end\":6128}"}, {"text": "So when it wants to make a checkpoint, it calls fork. And fork creates a copy of that process. Now we have the operating system running, and we have now basically two processes that correspond to this application. So the service raft. Service raft.", "metadataJson": "{\"start\":6130,\"end\":6149}"}, {"text": "And this is the copy. The child, the operating system, uses copy and write. So when it made a copy of that second process, it just copied the page table, but didn't copy physical memory. So basically these two processes share the same physical memory, which holds our key value store. And so now the idea is that the child, when it starts running, it starts making a checkpoint or snapshot.", "metadataJson": "{\"start\":6150,\"end\":6183}"}, {"text": "I can just write out the key value, sort of the key value store to disk. And in parallel, the parent can just start processing new get and put operations.", "metadataJson": "{\"start\":6183,\"end\":6198}"}, {"text": "Because if it does a put operation and it wants to modify, it will write to the pages that correspond to the key value store that will result in a page fault. And so the OS will get a page fault, and so the OS will copy that page at that point. And then you know, the first parent process can just update it. And this is all transparent to the child, right. Because the child, you know, had a consistent snapshot of the whole address space at the point of the fork.", "metadataJson": "{\"start\":6201,\"end\":6229}"}, {"text": "And so this allows basically the parent and child to run concurrently, still make a consistent snapshot and the parent to actually make process new boot and get operations. Is that more clear? Hopefully. Oh yeah. Okay, I see.", "metadataJson": "{\"start\":6230,\"end\":6245}"}, {"text": "So we copy and write the memory that holds the key value store. Okay. Okay. Okay, I see. Yeah, this makes it very clear.", "metadataJson": "{\"start\":6245,\"end\":6254}"}, {"text": "Thank you so much. You're welcome.", "metadataJson": "{\"start\":6254,\"end\":6257}"}, {"text": "Any more questions? Is there anybody like. Yeah, I have, I have. I guess this is sort of a weird scenario and I'm not sure if this could actually, but what if. So imagine that we're always in the same term and then you get to a point where some nodes have disconnected but they're still the same term, the leader is still in the same term, and then at some point they will, they will do a snapshot and then all the logs will be compressed and then they keep going forward.", "metadataJson": "{\"start\":6260,\"end\":6294}"}, {"text": "And now the logs are being populated again. And then let's just say 15 logs have been added and then after ten they compress them and then they're at index, they're index five again. And then the other nodes join back in and they're also at index five of the same terminal. Is that a problem? Like how does, it's almost like they're on a snapshot epoch of some sort.", "metadataJson": "{\"start\":6294,\"end\":6322}"}, {"text": "Okay, so the snapshots correspond to an index, right? So yeah, so, okay, let's maybe draw your scenario. So we got a server that has some log and, you know, maybe, I think, you know, you talked about ten and it took a snapshot at ten. Yeah, so let's say that basically. Yeah, so basically the first nine operations, or maybe including ten, are in the snapshot.", "metadataJson": "{\"start\":6323,\"end\":6350}"}, {"text": "And then, okay, so there's another note that is same term. So all these entries have the same term, right? Like whatever, you know, 111111, right? Yep, yep. And so this node actually, but this node has only through ten, Greg, and this guy has through 15, let's say.", "metadataJson": "{\"start\":6352,\"end\":6375}"}, {"text": "I think that's what you're saying. Correct, actually. So here were no ones, but here's a one.", "metadataJson": "{\"start\":6376,\"end\":6379}"}, {"text": "Well, I think my, my thought is, well, here's, here's a question I could answer. When you take a snapshot, do you reset your index or do you keep counting? You keep that. Oh, okay. I was imagining it was like an array and you saw your index goes backwards.", "metadataJson": "{\"start\":6384,\"end\":6401}"}, {"text": "So that if, so that it would be possible for you to have two different entries in the same term with the same index. Yeah, that's not allowed. Absolutely right. Exactly. Yeah.", "metadataJson": "{\"start\":6402,\"end\":6411}"}, {"text": "Okay, I see. So, okay. Okay, that makes sense. Never reset the index. Yeah.", "metadataJson": "{\"start\":6411,\"end\":6418}"}, {"text": "When you cut, like this part of the log, you know, the index stays at ten. Got it, got it. And so, in fact, you know, when you do this in 2d, this is going to be slightly annoying because you presumably take advantage of the fact that the start of the log is at zero. And what you're now going to get is that the start of the log might be ten.", "metadataJson": "{\"start\":6419,\"end\":6437}"}, {"text": "People have to have an offset of some sort. Yeah, you have to. Exactly. You have to add that offset everywhere. Yeah.", "metadataJson": "{\"start\":6439,\"end\":6447}"}, {"text": "Oh, and then last thing, really quickly, I think the reason I was confused earlier was in the code for lab two, there's a comment that says we're supposed to return immediately from start. Yeah. Yeah. Well, you. Oh, yes.", "metadataJson": "{\"start\":6447,\"end\":6464}"}, {"text": "Okay. So let me go back to this picture here. Hopefully it's getting really crowded. So we get an operation. Correct.", "metadataJson": "{\"start\":6466,\"end\":6475}"}, {"text": "And we do the start operation. We call start. Oh, return immediately doesn't necessarily mean reply. Is that. Yeah, exactly.", "metadataJson": "{\"start\":6475,\"end\":6483}"}, {"text": "Is that the idea? Yeah, exactly. It just means reply back. Return to the service, not to decline. I see, I see.", "metadataJson": "{\"start\":6483,\"end\":6491}"}, {"text": "Okay. Gotcha. Yeah. I guess operating under the assumption that a return always is necessarily a reply. But that's not.", "metadataJson": "{\"start\":6491,\"end\":6500}"}, {"text": "That's not always the case. No, it's not the case. I think this would become more clear in lab three than, you know, in lab two. There's a little bit weird. Correct.", "metadataJson": "{\"start\":6500,\"end\":6508}"}, {"text": "There's no. Really. There's no application. Really? Yeah.", "metadataJson": "{\"start\":6508,\"end\":6511}"}, {"text": "Yeah. Okay, well, thank you. This was really helpful. You're welcome. Happy.", "metadataJson": "{\"start\":6511,\"end\":6517}"}, {"text": "Appreciate it. Have a good one. Yeah, you too. Bye. Good luck with the lapse.", "metadataJson": "{\"start\":6517,\"end\":6526}"}]}